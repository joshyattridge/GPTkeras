{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 1.0067337512969972, "val_loss": 0.9486046218872071, "val_acc": 0.48}, {"epoch": 2, "train_loss": 0.8849996709823609, "val_loss": 0.8621234798431396, "val_acc": 0.62}, {"epoch": 3, "train_loss": 0.8115028691291809, "val_loss": 0.8022264242172241, "val_acc": 0.625}, {"epoch": 4, "train_loss": 0.7351275897026062, "val_loss": 0.7204679083824158, "val_acc": 0.71}, {"epoch": 5, "train_loss": 0.6702573442459107, "val_loss": 0.6614776492118836, "val_acc": 0.745}, {"epoch": 6, "train_loss": 0.6230600023269653, "val_loss": 0.6293046283721924, "val_acc": 0.7}, {"epoch": 7, "train_loss": 0.5724204540252685, "val_loss": 0.5763677334785462, "val_acc": 0.77}, {"epoch": 8, "train_loss": 0.5391963791847229, "val_loss": 0.5506830549240113, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.5158848261833191, "val_loss": 0.5331798553466797, "val_acc": 0.775}, {"epoch": 10, "train_loss": 0.5068857944011689, "val_loss": 0.5028002834320069, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.481302992105484, "val_loss": 0.5057082343101501, "val_acc": 0.78}, {"epoch": 12, "train_loss": 0.4715612351894379, "val_loss": 0.4817227506637573, "val_acc": 0.81}, {"epoch": 13, "train_loss": 0.4670651149749756, "val_loss": 0.48264613389968875, "val_acc": 0.79}, {"epoch": 14, "train_loss": 0.4556010210514069, "val_loss": 0.4762165117263794, "val_acc": 0.8}, {"epoch": 15, "train_loss": 0.44913923382759097, "val_loss": 0.4761407923698425, "val_acc": 0.785}, {"epoch": 16, "train_loss": 0.4393912923336029, "val_loss": 0.47137898206710815, "val_acc": 0.79}, {"epoch": 17, "train_loss": 0.43734227418899535, "val_loss": 0.4586651849746704, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.43485326766967775, "val_loss": 0.4705222225189209, "val_acc": 0.78}, {"epoch": 19, "train_loss": 0.43416388273239137, "val_loss": 0.45806352615356444, "val_acc": 0.795}, {"epoch": 20, "train_loss": 0.4270804274082184, "val_loss": 0.45139691829681394, "val_acc": 0.815}, {"epoch": 21, "train_loss": 0.4272925400733948, "val_loss": 0.4609017658233643, "val_acc": 0.795}, {"epoch": 22, "train_loss": 0.4343694758415222, "val_loss": 0.4610349702835083, "val_acc": 0.79}, {"epoch": 23, "train_loss": 0.42693010330200193, "val_loss": 0.4553215456008911, "val_acc": 0.79}, {"epoch": 24, "train_loss": 0.42645740032196044, "val_loss": 0.4537976336479187, "val_acc": 0.825}, {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}], "final_metrics": {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 1.0067337512969972, "val_loss": 0.9486046218872071, "val_acc": 0.48}, {"epoch": 2, "train_loss": 0.8849996709823609, "val_loss": 0.8621234798431396, "val_acc": 0.62}, {"epoch": 3, "train_loss": 0.8115028691291809, "val_loss": 0.8022264242172241, "val_acc": 0.625}, {"epoch": 4, "train_loss": 0.7351275897026062, "val_loss": 0.7204679083824158, "val_acc": 0.71}, {"epoch": 5, "train_loss": 0.6702573442459107, "val_loss": 0.6614776492118836, "val_acc": 0.745}, {"epoch": 6, "train_loss": 0.6230600023269653, "val_loss": 0.6293046283721924, "val_acc": 0.7}, {"epoch": 7, "train_loss": 0.5724204540252685, "val_loss": 0.5763677334785462, "val_acc": 0.77}, {"epoch": 8, "train_loss": 0.5391963791847229, "val_loss": 0.5506830549240113, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.5158848261833191, "val_loss": 0.5331798553466797, "val_acc": 0.775}, {"epoch": 10, "train_loss": 0.5068857944011689, "val_loss": 0.5028002834320069, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.481302992105484, "val_loss": 0.5057082343101501, "val_acc": 0.78}, {"epoch": 12, "train_loss": 0.4715612351894379, "val_loss": 0.4817227506637573, "val_acc": 0.81}, {"epoch": 13, "train_loss": 0.4670651149749756, "val_loss": 0.48264613389968875, "val_acc": 0.79}, {"epoch": 14, "train_loss": 0.4556010210514069, "val_loss": 0.4762165117263794, "val_acc": 0.8}, {"epoch": 15, "train_loss": 0.44913923382759097, "val_loss": 0.4761407923698425, "val_acc": 0.785}, {"epoch": 16, "train_loss": 0.4393912923336029, "val_loss": 0.47137898206710815, "val_acc": 0.79}, {"epoch": 17, "train_loss": 0.43734227418899535, "val_loss": 0.4586651849746704, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.43485326766967775, "val_loss": 0.4705222225189209, "val_acc": 0.78}, {"epoch": 19, "train_loss": 0.43416388273239137, "val_loss": 0.45806352615356444, "val_acc": 0.795}, {"epoch": 20, "train_loss": 0.4270804274082184, "val_loss": 0.45139691829681394, "val_acc": 0.815}, {"epoch": 21, "train_loss": 0.4272925400733948, "val_loss": 0.4609017658233643, "val_acc": 0.795}, {"epoch": 22, "train_loss": 0.4343694758415222, "val_loss": 0.4610349702835083, "val_acc": 0.79}, {"epoch": 23, "train_loss": 0.42693010330200193, "val_loss": 0.4553215456008911, "val_acc": 0.79}, {"epoch": 24, "train_loss": 0.42645740032196044, "val_loss": 0.4537976336479187, "val_acc": 0.825}, {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}], "final_metrics": {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 1.0067337512969972, "val_loss": 0.9486046218872071, "val_acc": 0.48}, {"epoch": 2, "train_loss": 0.8849996709823609, "val_loss": 0.8621234798431396, "val_acc": 0.62}, {"epoch": 3, "train_loss": 0.8115028691291809, "val_loss": 0.8022264242172241, "val_acc": 0.625}, {"epoch": 4, "train_loss": 0.7351275897026062, "val_loss": 0.7204679083824158, "val_acc": 0.71}, {"epoch": 5, "train_loss": 0.6702573442459107, "val_loss": 0.6614776492118836, "val_acc": 0.745}, {"epoch": 6, "train_loss": 0.6230600023269653, "val_loss": 0.6293046283721924, "val_acc": 0.7}, {"epoch": 7, "train_loss": 0.5724204540252685, "val_loss": 0.5763677334785462, "val_acc": 0.77}, {"epoch": 8, "train_loss": 0.5391963791847229, "val_loss": 0.5506830549240113, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.5158848261833191, "val_loss": 0.5331798553466797, "val_acc": 0.775}, {"epoch": 10, "train_loss": 0.5068857944011689, "val_loss": 0.5028002834320069, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.481302992105484, "val_loss": 0.5057082343101501, "val_acc": 0.78}, {"epoch": 12, "train_loss": 0.4715612351894379, "val_loss": 0.4817227506637573, "val_acc": 0.81}, {"epoch": 13, "train_loss": 0.4670651149749756, "val_loss": 0.48264613389968875, "val_acc": 0.79}, {"epoch": 14, "train_loss": 0.4556010210514069, "val_loss": 0.4762165117263794, "val_acc": 0.8}, {"epoch": 15, "train_loss": 0.44913923382759097, "val_loss": 0.4761407923698425, "val_acc": 0.785}, {"epoch": 16, "train_loss": 0.4393912923336029, "val_loss": 0.47137898206710815, "val_acc": 0.79}, {"epoch": 17, "train_loss": 0.43734227418899535, "val_loss": 0.4586651849746704, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.43485326766967775, "val_loss": 0.4705222225189209, "val_acc": 0.78}, {"epoch": 19, "train_loss": 0.43416388273239137, "val_loss": 0.45806352615356444, "val_acc": 0.795}, {"epoch": 20, "train_loss": 0.4270804274082184, "val_loss": 0.45139691829681394, "val_acc": 0.815}, {"epoch": 21, "train_loss": 0.4272925400733948, "val_loss": 0.4609017658233643, "val_acc": 0.795}, {"epoch": 22, "train_loss": 0.4343694758415222, "val_loss": 0.4610349702835083, "val_acc": 0.79}, {"epoch": 23, "train_loss": 0.42693010330200193, "val_loss": 0.4553215456008911, "val_acc": 0.79}, {"epoch": 24, "train_loss": 0.42645740032196044, "val_loss": 0.4537976336479187, "val_acc": 0.825}, {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}], "final_metrics": {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 1.0067337512969972, "val_loss": 0.9486046218872071, "val_acc": 0.48}, {"epoch": 2, "train_loss": 0.8849996709823609, "val_loss": 0.8621234798431396, "val_acc": 0.62}, {"epoch": 3, "train_loss": 0.8115028691291809, "val_loss": 0.8022264242172241, "val_acc": 0.625}, {"epoch": 4, "train_loss": 0.7351275897026062, "val_loss": 0.7204679083824158, "val_acc": 0.71}, {"epoch": 5, "train_loss": 0.6702573442459107, "val_loss": 0.6614776492118836, "val_acc": 0.745}, {"epoch": 6, "train_loss": 0.6230600023269653, "val_loss": 0.6293046283721924, "val_acc": 0.7}, {"epoch": 7, "train_loss": 0.5724204540252685, "val_loss": 0.5763677334785462, "val_acc": 0.77}, {"epoch": 8, "train_loss": 0.5391963791847229, "val_loss": 0.5506830549240113, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.5158848261833191, "val_loss": 0.5331798553466797, "val_acc": 0.775}, {"epoch": 10, "train_loss": 0.5068857944011689, "val_loss": 0.5028002834320069, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.481302992105484, "val_loss": 0.5057082343101501, "val_acc": 0.78}, {"epoch": 12, "train_loss": 0.4715612351894379, "val_loss": 0.4817227506637573, "val_acc": 0.81}, {"epoch": 13, "train_loss": 0.4670651149749756, "val_loss": 0.48264613389968875, "val_acc": 0.79}, {"epoch": 14, "train_loss": 0.4556010210514069, "val_loss": 0.4762165117263794, "val_acc": 0.8}, {"epoch": 15, "train_loss": 0.44913923382759097, "val_loss": 0.4761407923698425, "val_acc": 0.785}, {"epoch": 16, "train_loss": 0.4393912923336029, "val_loss": 0.47137898206710815, "val_acc": 0.79}, {"epoch": 17, "train_loss": 0.43734227418899535, "val_loss": 0.4586651849746704, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.43485326766967775, "val_loss": 0.4705222225189209, "val_acc": 0.78}, {"epoch": 19, "train_loss": 0.43416388273239137, "val_loss": 0.45806352615356444, "val_acc": 0.795}, {"epoch": 20, "train_loss": 0.4270804274082184, "val_loss": 0.45139691829681394, "val_acc": 0.815}, {"epoch": 21, "train_loss": 0.4272925400733948, "val_loss": 0.4609017658233643, "val_acc": 0.795}, {"epoch": 22, "train_loss": 0.4343694758415222, "val_loss": 0.4610349702835083, "val_acc": 0.79}, {"epoch": 23, "train_loss": 0.42693010330200193, "val_loss": 0.4553215456008911, "val_acc": 0.79}, {"epoch": 24, "train_loss": 0.42645740032196044, "val_loss": 0.4537976336479187, "val_acc": 0.825}, {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}], "final_metrics": {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 0.9843513011932373, "val_loss": 0.9047394967079163, "val_acc": 0.58}, {"epoch": 2, "train_loss": 0.8216707110404968, "val_loss": 0.7304354548454285, "val_acc": 0.615}, {"epoch": 3, "train_loss": 0.644498143196106, "val_loss": 0.5736521720886231, "val_acc": 0.765}, {"epoch": 4, "train_loss": 0.5265160298347473, "val_loss": 0.48795778274536133, "val_acc": 0.8}, {"epoch": 5, "train_loss": 0.4809634304046631, "val_loss": 0.485700216293335, "val_acc": 0.77}, {"epoch": 6, "train_loss": 0.47356014132499696, "val_loss": 0.43869666576385496, "val_acc": 0.84}, {"epoch": 7, "train_loss": 0.46164268255233765, "val_loss": 0.4357795214653015, "val_acc": 0.795}, {"epoch": 8, "train_loss": 0.46565366148948667, "val_loss": 0.5257364082336425, "val_acc": 0.77}, {"epoch": 9, "train_loss": 0.4681847643852234, "val_loss": 0.4632417726516724, "val_acc": 0.805}, {"epoch": 10, "train_loss": 0.44565892457962036, "val_loss": 0.4130148732662201, "val_acc": 0.79}, {"epoch": 11, "train_loss": 0.4438547670841217, "val_loss": 0.42187091827392575, "val_acc": 0.825}, {"epoch": 12, "train_loss": 0.4481248068809509, "val_loss": 0.41947678565979, "val_acc": 0.82}, {"epoch": 13, "train_loss": 0.44476788997650146, "val_loss": 0.4160110902786255, "val_acc": 0.82}, {"epoch": 14, "train_loss": 0.45466936826705934, "val_loss": 0.4393052566051483, "val_acc": 0.785}, {"epoch": 15, "train_loss": 0.4417376351356506, "val_loss": 0.4201365077495575, "val_acc": 0.805}, {"epoch": 16, "train_loss": 0.43338008642196657, "val_loss": 0.42957635164260866, "val_acc": 0.825}, {"epoch": 17, "train_loss": 0.42896307706832887, "val_loss": 0.44648670077323915, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.44044565558433535, "val_loss": 0.43951432466506957, "val_acc": 0.79}, {"epoch": 19, "train_loss": 0.45230750799179076, "val_loss": 0.4247144865989685, "val_acc": 0.79}, {"epoch": 20, "train_loss": 0.4673351335525513, "val_loss": 0.5026200127601623, "val_acc": 0.745}, {"epoch": 21, "train_loss": 0.4921862268447876, "val_loss": 0.41918158531188965, "val_acc": 0.82}, {"epoch": 22, "train_loss": 0.45764703273773194, "val_loss": 0.47118751287460325, "val_acc": 0.785}, {"epoch": 23, "train_loss": 0.4542748785018921, "val_loss": 0.4330461525917053, "val_acc": 0.81}, {"epoch": 24, "train_loss": 0.42691744565963746, "val_loss": 0.4137323522567749, "val_acc": 0.805}, {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}], "final_metrics": {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 0.9843513011932373, "val_loss": 0.9047394967079163, "val_acc": 0.58}, {"epoch": 2, "train_loss": 0.8216707110404968, "val_loss": 0.7304354548454285, "val_acc": 0.615}, {"epoch": 3, "train_loss": 0.644498143196106, "val_loss": 0.5736521720886231, "val_acc": 0.765}, {"epoch": 4, "train_loss": 0.5265160298347473, "val_loss": 0.48795778274536133, "val_acc": 0.8}, {"epoch": 5, "train_loss": 0.4809634304046631, "val_loss": 0.485700216293335, "val_acc": 0.77}, {"epoch": 6, "train_loss": 0.47356014132499696, "val_loss": 0.43869666576385496, "val_acc": 0.84}, {"epoch": 7, "train_loss": 0.46164268255233765, "val_loss": 0.4357795214653015, "val_acc": 0.795}, {"epoch": 8, "train_loss": 0.46565366148948667, "val_loss": 0.5257364082336425, "val_acc": 0.77}, {"epoch": 9, "train_loss": 0.4681847643852234, "val_loss": 0.4632417726516724, "val_acc": 0.805}, {"epoch": 10, "train_loss": 0.44565892457962036, "val_loss": 0.4130148732662201, "val_acc": 0.79}, {"epoch": 11, "train_loss": 0.4438547670841217, "val_loss": 0.42187091827392575, "val_acc": 0.825}, {"epoch": 12, "train_loss": 0.4481248068809509, "val_loss": 0.41947678565979, "val_acc": 0.82}, {"epoch": 13, "train_loss": 0.44476788997650146, "val_loss": 0.4160110902786255, "val_acc": 0.82}, {"epoch": 14, "train_loss": 0.45466936826705934, "val_loss": 0.4393052566051483, "val_acc": 0.785}, {"epoch": 15, "train_loss": 0.4417376351356506, "val_loss": 0.4201365077495575, "val_acc": 0.805}, {"epoch": 16, "train_loss": 0.43338008642196657, "val_loss": 0.42957635164260866, "val_acc": 0.825}, {"epoch": 17, "train_loss": 0.42896307706832887, "val_loss": 0.44648670077323915, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.44044565558433535, "val_loss": 0.43951432466506957, "val_acc": 0.79}, {"epoch": 19, "train_loss": 0.45230750799179076, "val_loss": 0.4247144865989685, "val_acc": 0.79}, {"epoch": 20, "train_loss": 0.4673351335525513, "val_loss": 0.5026200127601623, "val_acc": 0.745}, {"epoch": 21, "train_loss": 0.4921862268447876, "val_loss": 0.41918158531188965, "val_acc": 0.82}, {"epoch": 22, "train_loss": 0.45764703273773194, "val_loss": 0.47118751287460325, "val_acc": 0.785}, {"epoch": 23, "train_loss": 0.4542748785018921, "val_loss": 0.4330461525917053, "val_acc": 0.81}, {"epoch": 24, "train_loss": 0.42691744565963746, "val_loss": 0.4137323522567749, "val_acc": 0.805}, {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}], "final_metrics": {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 3))", "history": [{"epoch": 1, "train_loss": 0.9233387351036072, "val_loss": 0.7337618398666382, "val_acc": 0.635}, {"epoch": 2, "train_loss": 0.6119428086280823, "val_loss": 0.5381832480430603, "val_acc": 0.765}, {"epoch": 3, "train_loss": 0.47736916661262513, "val_loss": 0.5048772621154786, "val_acc": 0.765}, {"epoch": 4, "train_loss": 0.4529802858829498, "val_loss": 0.521127028465271, "val_acc": 0.77}, {"epoch": 5, "train_loss": 0.4556947362422943, "val_loss": 0.5043503403663635, "val_acc": 0.785}, {"epoch": 6, "train_loss": 0.4485176587104797, "val_loss": 0.525751895904541, "val_acc": 0.77}, {"epoch": 7, "train_loss": 0.4507916975021362, "val_loss": 0.5356218051910401, "val_acc": 0.745}, {"epoch": 8, "train_loss": 0.464043105840683, "val_loss": 0.48687992811203, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.42306200265884397, "val_loss": 0.487814838886261, "val_acc": 0.77}, {"epoch": 10, "train_loss": 0.43314430832862855, "val_loss": 0.49453447341918944, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.4319250214099884, "val_loss": 0.4698318541049957, "val_acc": 0.765}, {"epoch": 12, "train_loss": 0.42940823912620546, "val_loss": 0.47184057712554933, "val_acc": 0.785}, {"epoch": 13, "train_loss": 0.4121372807025909, "val_loss": 0.4870171666145325, "val_acc": 0.785}, {"epoch": 14, "train_loss": 0.42170664072036745, "val_loss": 0.4849669313430786, "val_acc": 0.78}, {"epoch": 15, "train_loss": 0.4161202108860016, "val_loss": 0.46417582631111143, "val_acc": 0.79}, {"epoch": 16, "train_loss": 0.4312313485145569, "val_loss": 0.5144489467144012, "val_acc": 0.77}, {"epoch": 17, "train_loss": 0.43907368898391724, "val_loss": 0.48780232906341553, "val_acc": 0.775}, {"epoch": 18, "train_loss": 0.4226838719844818, "val_loss": 0.48226341247558596, "val_acc": 0.775}, {"epoch": 19, "train_loss": 0.4212912058830261, "val_loss": 0.49470561504364013, "val_acc": 0.765}, {"epoch": 20, "train_loss": 0.42774937987327577, "val_loss": 0.48950278759002686, "val_acc": 0.775}, {"epoch": 21, "train_loss": 0.4480937576293945, "val_loss": 0.4906191110610962, "val_acc": 0.755}, {"epoch": 22, "train_loss": 0.4185711395740509, "val_loss": 0.5084364175796509, "val_acc": 0.775}, {"epoch": 23, "train_loss": 0.42288042783737184, "val_loss": 0.4917571520805359, "val_acc": 0.76}, {"epoch": 24, "train_loss": 0.4216306734085083, "val_loss": 0.4927514278888702, "val_acc": 0.775}, {"epoch": 25, "train_loss": 0.4291934835910797, "val_loss": 0.49987715125083926, "val_acc": 0.775}], "final_metrics": {"epoch": 25, "train_loss": 0.4291934835910797, "val_loss": 0.49987715125083926, "val_acc": 0.775}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 0.9843513011932373, "val_loss": 0.9047394967079163, "val_acc": 0.58}, {"epoch": 2, "train_loss": 0.8216707110404968, "val_loss": 0.7304354548454285, "val_acc": 0.615}, {"epoch": 3, "train_loss": 0.644498143196106, "val_loss": 0.5736521720886231, "val_acc": 0.765}, {"epoch": 4, "train_loss": 0.5265160298347473, "val_loss": 0.48795778274536133, "val_acc": 0.8}, {"epoch": 5, "train_loss": 0.4809634304046631, "val_loss": 0.485700216293335, "val_acc": 0.77}, {"epoch": 6, "train_loss": 0.47356014132499696, "val_loss": 0.43869666576385496, "val_acc": 0.84}, {"epoch": 7, "train_loss": 0.46164268255233765, "val_loss": 0.4357795214653015, "val_acc": 0.795}, {"epoch": 8, "train_loss": 0.46565366148948667, "val_loss": 0.5257364082336425, "val_acc": 0.77}, {"epoch": 9, "train_loss": 0.4681847643852234, "val_loss": 0.4632417726516724, "val_acc": 0.805}, {"epoch": 10, "train_loss": 0.44565892457962036, "val_loss": 0.4130148732662201, "val_acc": 0.79}, {"epoch": 11, "train_loss": 0.4438547670841217, "val_loss": 0.42187091827392575, "val_acc": 0.825}, {"epoch": 12, "train_loss": 0.4481248068809509, "val_loss": 0.41947678565979, "val_acc": 0.82}, {"epoch": 13, "train_loss": 0.44476788997650146, "val_loss": 0.4160110902786255, "val_acc": 0.82}, {"epoch": 14, "train_loss": 0.45466936826705934, "val_loss": 0.4393052566051483, "val_acc": 0.785}, {"epoch": 15, "train_loss": 0.4417376351356506, "val_loss": 0.4201365077495575, "val_acc": 0.805}, {"epoch": 16, "train_loss": 0.43338008642196657, "val_loss": 0.42957635164260866, "val_acc": 0.825}, {"epoch": 17, "train_loss": 0.42896307706832887, "val_loss": 0.44648670077323915, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.44044565558433535, "val_loss": 0.43951432466506957, "val_acc": 0.79}, {"epoch": 19, "train_loss": 0.45230750799179076, "val_loss": 0.4247144865989685, "val_acc": 0.79}, {"epoch": 20, "train_loss": 0.4673351335525513, "val_loss": 0.5026200127601623, "val_acc": 0.745}, {"epoch": 21, "train_loss": 0.4921862268447876, "val_loss": 0.41918158531188965, "val_acc": 0.82}, {"epoch": 22, "train_loss": 0.45764703273773194, "val_loss": 0.47118751287460325, "val_acc": 0.785}, {"epoch": 23, "train_loss": 0.4542748785018921, "val_loss": 0.4330461525917053, "val_acc": 0.81}, {"epoch": 24, "train_loss": 0.42691744565963746, "val_loss": 0.4137323522567749, "val_acc": 0.805}, {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}], "final_metrics": {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}}

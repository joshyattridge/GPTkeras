{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 1.0067337512969972, "val_loss": 0.9486046218872071, "val_acc": 0.48}, {"epoch": 2, "train_loss": 0.8849996709823609, "val_loss": 0.8621234798431396, "val_acc": 0.62}, {"epoch": 3, "train_loss": 0.8115028691291809, "val_loss": 0.8022264242172241, "val_acc": 0.625}, {"epoch": 4, "train_loss": 0.7351275897026062, "val_loss": 0.7204679083824158, "val_acc": 0.71}, {"epoch": 5, "train_loss": 0.6702573442459107, "val_loss": 0.6614776492118836, "val_acc": 0.745}, {"epoch": 6, "train_loss": 0.6230600023269653, "val_loss": 0.6293046283721924, "val_acc": 0.7}, {"epoch": 7, "train_loss": 0.5724204540252685, "val_loss": 0.5763677334785462, "val_acc": 0.77}, {"epoch": 8, "train_loss": 0.5391963791847229, "val_loss": 0.5506830549240113, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.5158848261833191, "val_loss": 0.5331798553466797, "val_acc": 0.775}, {"epoch": 10, "train_loss": 0.5068857944011689, "val_loss": 0.5028002834320069, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.481302992105484, "val_loss": 0.5057082343101501, "val_acc": 0.78}, {"epoch": 12, "train_loss": 0.4715612351894379, "val_loss": 0.4817227506637573, "val_acc": 0.81}, {"epoch": 13, "train_loss": 0.4670651149749756, "val_loss": 0.48264613389968875, "val_acc": 0.79}, {"epoch": 14, "train_loss": 0.4556010210514069, "val_loss": 0.4762165117263794, "val_acc": 0.8}, {"epoch": 15, "train_loss": 0.44913923382759097, "val_loss": 0.4761407923698425, "val_acc": 0.785}, {"epoch": 16, "train_loss": 0.4393912923336029, "val_loss": 0.47137898206710815, "val_acc": 0.79}, {"epoch": 17, "train_loss": 0.43734227418899535, "val_loss": 0.4586651849746704, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.43485326766967775, "val_loss": 0.4705222225189209, "val_acc": 0.78}, {"epoch": 19, "train_loss": 0.43416388273239137, "val_loss": 0.45806352615356444, "val_acc": 0.795}, {"epoch": 20, "train_loss": 0.4270804274082184, "val_loss": 0.45139691829681394, "val_acc": 0.815}, {"epoch": 21, "train_loss": 0.4272925400733948, "val_loss": 0.4609017658233643, "val_acc": 0.795}, {"epoch": 22, "train_loss": 0.4343694758415222, "val_loss": 0.4610349702835083, "val_acc": 0.79}, {"epoch": 23, "train_loss": 0.42693010330200193, "val_loss": 0.4553215456008911, "val_acc": 0.79}, {"epoch": 24, "train_loss": 0.42645740032196044, "val_loss": 0.4537976336479187, "val_acc": 0.825}, {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}], "final_metrics": {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 1.0067337512969972, "val_loss": 0.9486046218872071, "val_acc": 0.48}, {"epoch": 2, "train_loss": 0.8849996709823609, "val_loss": 0.8621234798431396, "val_acc": 0.62}, {"epoch": 3, "train_loss": 0.8115028691291809, "val_loss": 0.8022264242172241, "val_acc": 0.625}, {"epoch": 4, "train_loss": 0.7351275897026062, "val_loss": 0.7204679083824158, "val_acc": 0.71}, {"epoch": 5, "train_loss": 0.6702573442459107, "val_loss": 0.6614776492118836, "val_acc": 0.745}, {"epoch": 6, "train_loss": 0.6230600023269653, "val_loss": 0.6293046283721924, "val_acc": 0.7}, {"epoch": 7, "train_loss": 0.5724204540252685, "val_loss": 0.5763677334785462, "val_acc": 0.77}, {"epoch": 8, "train_loss": 0.5391963791847229, "val_loss": 0.5506830549240113, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.5158848261833191, "val_loss": 0.5331798553466797, "val_acc": 0.775}, {"epoch": 10, "train_loss": 0.5068857944011689, "val_loss": 0.5028002834320069, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.481302992105484, "val_loss": 0.5057082343101501, "val_acc": 0.78}, {"epoch": 12, "train_loss": 0.4715612351894379, "val_loss": 0.4817227506637573, "val_acc": 0.81}, {"epoch": 13, "train_loss": 0.4670651149749756, "val_loss": 0.48264613389968875, "val_acc": 0.79}, {"epoch": 14, "train_loss": 0.4556010210514069, "val_loss": 0.4762165117263794, "val_acc": 0.8}, {"epoch": 15, "train_loss": 0.44913923382759097, "val_loss": 0.4761407923698425, "val_acc": 0.785}, {"epoch": 16, "train_loss": 0.4393912923336029, "val_loss": 0.47137898206710815, "val_acc": 0.79}, {"epoch": 17, "train_loss": 0.43734227418899535, "val_loss": 0.4586651849746704, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.43485326766967775, "val_loss": 0.4705222225189209, "val_acc": 0.78}, {"epoch": 19, "train_loss": 0.43416388273239137, "val_loss": 0.45806352615356444, "val_acc": 0.795}, {"epoch": 20, "train_loss": 0.4270804274082184, "val_loss": 0.45139691829681394, "val_acc": 0.815}, {"epoch": 21, "train_loss": 0.4272925400733948, "val_loss": 0.4609017658233643, "val_acc": 0.795}, {"epoch": 22, "train_loss": 0.4343694758415222, "val_loss": 0.4610349702835083, "val_acc": 0.79}, {"epoch": 23, "train_loss": 0.42693010330200193, "val_loss": 0.4553215456008911, "val_acc": 0.79}, {"epoch": 24, "train_loss": 0.42645740032196044, "val_loss": 0.4537976336479187, "val_acc": 0.825}, {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}], "final_metrics": {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 1.0067337512969972, "val_loss": 0.9486046218872071, "val_acc": 0.48}, {"epoch": 2, "train_loss": 0.8849996709823609, "val_loss": 0.8621234798431396, "val_acc": 0.62}, {"epoch": 3, "train_loss": 0.8115028691291809, "val_loss": 0.8022264242172241, "val_acc": 0.625}, {"epoch": 4, "train_loss": 0.7351275897026062, "val_loss": 0.7204679083824158, "val_acc": 0.71}, {"epoch": 5, "train_loss": 0.6702573442459107, "val_loss": 0.6614776492118836, "val_acc": 0.745}, {"epoch": 6, "train_loss": 0.6230600023269653, "val_loss": 0.6293046283721924, "val_acc": 0.7}, {"epoch": 7, "train_loss": 0.5724204540252685, "val_loss": 0.5763677334785462, "val_acc": 0.77}, {"epoch": 8, "train_loss": 0.5391963791847229, "val_loss": 0.5506830549240113, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.5158848261833191, "val_loss": 0.5331798553466797, "val_acc": 0.775}, {"epoch": 10, "train_loss": 0.5068857944011689, "val_loss": 0.5028002834320069, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.481302992105484, "val_loss": 0.5057082343101501, "val_acc": 0.78}, {"epoch": 12, "train_loss": 0.4715612351894379, "val_loss": 0.4817227506637573, "val_acc": 0.81}, {"epoch": 13, "train_loss": 0.4670651149749756, "val_loss": 0.48264613389968875, "val_acc": 0.79}, {"epoch": 14, "train_loss": 0.4556010210514069, "val_loss": 0.4762165117263794, "val_acc": 0.8}, {"epoch": 15, "train_loss": 0.44913923382759097, "val_loss": 0.4761407923698425, "val_acc": 0.785}, {"epoch": 16, "train_loss": 0.4393912923336029, "val_loss": 0.47137898206710815, "val_acc": 0.79}, {"epoch": 17, "train_loss": 0.43734227418899535, "val_loss": 0.4586651849746704, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.43485326766967775, "val_loss": 0.4705222225189209, "val_acc": 0.78}, {"epoch": 19, "train_loss": 0.43416388273239137, "val_loss": 0.45806352615356444, "val_acc": 0.795}, {"epoch": 20, "train_loss": 0.4270804274082184, "val_loss": 0.45139691829681394, "val_acc": 0.815}, {"epoch": 21, "train_loss": 0.4272925400733948, "val_loss": 0.4609017658233643, "val_acc": 0.795}, {"epoch": 22, "train_loss": 0.4343694758415222, "val_loss": 0.4610349702835083, "val_acc": 0.79}, {"epoch": 23, "train_loss": 0.42693010330200193, "val_loss": 0.4553215456008911, "val_acc": 0.79}, {"epoch": 24, "train_loss": 0.42645740032196044, "val_loss": 0.4537976336479187, "val_acc": 0.825}, {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}], "final_metrics": {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 1.0067337512969972, "val_loss": 0.9486046218872071, "val_acc": 0.48}, {"epoch": 2, "train_loss": 0.8849996709823609, "val_loss": 0.8621234798431396, "val_acc": 0.62}, {"epoch": 3, "train_loss": 0.8115028691291809, "val_loss": 0.8022264242172241, "val_acc": 0.625}, {"epoch": 4, "train_loss": 0.7351275897026062, "val_loss": 0.7204679083824158, "val_acc": 0.71}, {"epoch": 5, "train_loss": 0.6702573442459107, "val_loss": 0.6614776492118836, "val_acc": 0.745}, {"epoch": 6, "train_loss": 0.6230600023269653, "val_loss": 0.6293046283721924, "val_acc": 0.7}, {"epoch": 7, "train_loss": 0.5724204540252685, "val_loss": 0.5763677334785462, "val_acc": 0.77}, {"epoch": 8, "train_loss": 0.5391963791847229, "val_loss": 0.5506830549240113, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.5158848261833191, "val_loss": 0.5331798553466797, "val_acc": 0.775}, {"epoch": 10, "train_loss": 0.5068857944011689, "val_loss": 0.5028002834320069, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.481302992105484, "val_loss": 0.5057082343101501, "val_acc": 0.78}, {"epoch": 12, "train_loss": 0.4715612351894379, "val_loss": 0.4817227506637573, "val_acc": 0.81}, {"epoch": 13, "train_loss": 0.4670651149749756, "val_loss": 0.48264613389968875, "val_acc": 0.79}, {"epoch": 14, "train_loss": 0.4556010210514069, "val_loss": 0.4762165117263794, "val_acc": 0.8}, {"epoch": 15, "train_loss": 0.44913923382759097, "val_loss": 0.4761407923698425, "val_acc": 0.785}, {"epoch": 16, "train_loss": 0.4393912923336029, "val_loss": 0.47137898206710815, "val_acc": 0.79}, {"epoch": 17, "train_loss": 0.43734227418899535, "val_loss": 0.4586651849746704, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.43485326766967775, "val_loss": 0.4705222225189209, "val_acc": 0.78}, {"epoch": 19, "train_loss": 0.43416388273239137, "val_loss": 0.45806352615356444, "val_acc": 0.795}, {"epoch": 20, "train_loss": 0.4270804274082184, "val_loss": 0.45139691829681394, "val_acc": 0.815}, {"epoch": 21, "train_loss": 0.4272925400733948, "val_loss": 0.4609017658233643, "val_acc": 0.795}, {"epoch": 22, "train_loss": 0.4343694758415222, "val_loss": 0.4610349702835083, "val_acc": 0.79}, {"epoch": 23, "train_loss": 0.42693010330200193, "val_loss": 0.4553215456008911, "val_acc": 0.79}, {"epoch": 24, "train_loss": 0.42645740032196044, "val_loss": 0.4537976336479187, "val_acc": 0.825}, {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}], "final_metrics": {"epoch": 25, "train_loss": 0.425895471572876, "val_loss": 0.4554232311248779, "val_acc": 0.79}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 0.9843513011932373, "val_loss": 0.9047394967079163, "val_acc": 0.58}, {"epoch": 2, "train_loss": 0.8216707110404968, "val_loss": 0.7304354548454285, "val_acc": 0.615}, {"epoch": 3, "train_loss": 0.644498143196106, "val_loss": 0.5736521720886231, "val_acc": 0.765}, {"epoch": 4, "train_loss": 0.5265160298347473, "val_loss": 0.48795778274536133, "val_acc": 0.8}, {"epoch": 5, "train_loss": 0.4809634304046631, "val_loss": 0.485700216293335, "val_acc": 0.77}, {"epoch": 6, "train_loss": 0.47356014132499696, "val_loss": 0.43869666576385496, "val_acc": 0.84}, {"epoch": 7, "train_loss": 0.46164268255233765, "val_loss": 0.4357795214653015, "val_acc": 0.795}, {"epoch": 8, "train_loss": 0.46565366148948667, "val_loss": 0.5257364082336425, "val_acc": 0.77}, {"epoch": 9, "train_loss": 0.4681847643852234, "val_loss": 0.4632417726516724, "val_acc": 0.805}, {"epoch": 10, "train_loss": 0.44565892457962036, "val_loss": 0.4130148732662201, "val_acc": 0.79}, {"epoch": 11, "train_loss": 0.4438547670841217, "val_loss": 0.42187091827392575, "val_acc": 0.825}, {"epoch": 12, "train_loss": 0.4481248068809509, "val_loss": 0.41947678565979, "val_acc": 0.82}, {"epoch": 13, "train_loss": 0.44476788997650146, "val_loss": 0.4160110902786255, "val_acc": 0.82}, {"epoch": 14, "train_loss": 0.45466936826705934, "val_loss": 0.4393052566051483, "val_acc": 0.785}, {"epoch": 15, "train_loss": 0.4417376351356506, "val_loss": 0.4201365077495575, "val_acc": 0.805}, {"epoch": 16, "train_loss": 0.43338008642196657, "val_loss": 0.42957635164260866, "val_acc": 0.825}, {"epoch": 17, "train_loss": 0.42896307706832887, "val_loss": 0.44648670077323915, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.44044565558433535, "val_loss": 0.43951432466506957, "val_acc": 0.79}, {"epoch": 19, "train_loss": 0.45230750799179076, "val_loss": 0.4247144865989685, "val_acc": 0.79}, {"epoch": 20, "train_loss": 0.4673351335525513, "val_loss": 0.5026200127601623, "val_acc": 0.745}, {"epoch": 21, "train_loss": 0.4921862268447876, "val_loss": 0.41918158531188965, "val_acc": 0.82}, {"epoch": 22, "train_loss": 0.45764703273773194, "val_loss": 0.47118751287460325, "val_acc": 0.785}, {"epoch": 23, "train_loss": 0.4542748785018921, "val_loss": 0.4330461525917053, "val_acc": 0.81}, {"epoch": 24, "train_loss": 0.42691744565963746, "val_loss": 0.4137323522567749, "val_acc": 0.805}, {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}], "final_metrics": {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 0.9843513011932373, "val_loss": 0.9047394967079163, "val_acc": 0.58}, {"epoch": 2, "train_loss": 0.8216707110404968, "val_loss": 0.7304354548454285, "val_acc": 0.615}, {"epoch": 3, "train_loss": 0.644498143196106, "val_loss": 0.5736521720886231, "val_acc": 0.765}, {"epoch": 4, "train_loss": 0.5265160298347473, "val_loss": 0.48795778274536133, "val_acc": 0.8}, {"epoch": 5, "train_loss": 0.4809634304046631, "val_loss": 0.485700216293335, "val_acc": 0.77}, {"epoch": 6, "train_loss": 0.47356014132499696, "val_loss": 0.43869666576385496, "val_acc": 0.84}, {"epoch": 7, "train_loss": 0.46164268255233765, "val_loss": 0.4357795214653015, "val_acc": 0.795}, {"epoch": 8, "train_loss": 0.46565366148948667, "val_loss": 0.5257364082336425, "val_acc": 0.77}, {"epoch": 9, "train_loss": 0.4681847643852234, "val_loss": 0.4632417726516724, "val_acc": 0.805}, {"epoch": 10, "train_loss": 0.44565892457962036, "val_loss": 0.4130148732662201, "val_acc": 0.79}, {"epoch": 11, "train_loss": 0.4438547670841217, "val_loss": 0.42187091827392575, "val_acc": 0.825}, {"epoch": 12, "train_loss": 0.4481248068809509, "val_loss": 0.41947678565979, "val_acc": 0.82}, {"epoch": 13, "train_loss": 0.44476788997650146, "val_loss": 0.4160110902786255, "val_acc": 0.82}, {"epoch": 14, "train_loss": 0.45466936826705934, "val_loss": 0.4393052566051483, "val_acc": 0.785}, {"epoch": 15, "train_loss": 0.4417376351356506, "val_loss": 0.4201365077495575, "val_acc": 0.805}, {"epoch": 16, "train_loss": 0.43338008642196657, "val_loss": 0.42957635164260866, "val_acc": 0.825}, {"epoch": 17, "train_loss": 0.42896307706832887, "val_loss": 0.44648670077323915, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.44044565558433535, "val_loss": 0.43951432466506957, "val_acc": 0.79}, {"epoch": 19, "train_loss": 0.45230750799179076, "val_loss": 0.4247144865989685, "val_acc": 0.79}, {"epoch": 20, "train_loss": 0.4673351335525513, "val_loss": 0.5026200127601623, "val_acc": 0.745}, {"epoch": 21, "train_loss": 0.4921862268447876, "val_loss": 0.41918158531188965, "val_acc": 0.82}, {"epoch": 22, "train_loss": 0.45764703273773194, "val_loss": 0.47118751287460325, "val_acc": 0.785}, {"epoch": 23, "train_loss": 0.4542748785018921, "val_loss": 0.4330461525917053, "val_acc": 0.81}, {"epoch": 24, "train_loss": 0.42691744565963746, "val_loss": 0.4137323522567749, "val_acc": 0.805}, {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}], "final_metrics": {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 3))", "history": [{"epoch": 1, "train_loss": 0.9233387351036072, "val_loss": 0.7337618398666382, "val_acc": 0.635}, {"epoch": 2, "train_loss": 0.6119428086280823, "val_loss": 0.5381832480430603, "val_acc": 0.765}, {"epoch": 3, "train_loss": 0.47736916661262513, "val_loss": 0.5048772621154786, "val_acc": 0.765}, {"epoch": 4, "train_loss": 0.4529802858829498, "val_loss": 0.521127028465271, "val_acc": 0.77}, {"epoch": 5, "train_loss": 0.4556947362422943, "val_loss": 0.5043503403663635, "val_acc": 0.785}, {"epoch": 6, "train_loss": 0.4485176587104797, "val_loss": 0.525751895904541, "val_acc": 0.77}, {"epoch": 7, "train_loss": 0.4507916975021362, "val_loss": 0.5356218051910401, "val_acc": 0.745}, {"epoch": 8, "train_loss": 0.464043105840683, "val_loss": 0.48687992811203, "val_acc": 0.78}, {"epoch": 9, "train_loss": 0.42306200265884397, "val_loss": 0.487814838886261, "val_acc": 0.77}, {"epoch": 10, "train_loss": 0.43314430832862855, "val_loss": 0.49453447341918944, "val_acc": 0.795}, {"epoch": 11, "train_loss": 0.4319250214099884, "val_loss": 0.4698318541049957, "val_acc": 0.765}, {"epoch": 12, "train_loss": 0.42940823912620546, "val_loss": 0.47184057712554933, "val_acc": 0.785}, {"epoch": 13, "train_loss": 0.4121372807025909, "val_loss": 0.4870171666145325, "val_acc": 0.785}, {"epoch": 14, "train_loss": 0.42170664072036745, "val_loss": 0.4849669313430786, "val_acc": 0.78}, {"epoch": 15, "train_loss": 0.4161202108860016, "val_loss": 0.46417582631111143, "val_acc": 0.79}, {"epoch": 16, "train_loss": 0.4312313485145569, "val_loss": 0.5144489467144012, "val_acc": 0.77}, {"epoch": 17, "train_loss": 0.43907368898391724, "val_loss": 0.48780232906341553, "val_acc": 0.775}, {"epoch": 18, "train_loss": 0.4226838719844818, "val_loss": 0.48226341247558596, "val_acc": 0.775}, {"epoch": 19, "train_loss": 0.4212912058830261, "val_loss": 0.49470561504364013, "val_acc": 0.765}, {"epoch": 20, "train_loss": 0.42774937987327577, "val_loss": 0.48950278759002686, "val_acc": 0.775}, {"epoch": 21, "train_loss": 0.4480937576293945, "val_loss": 0.4906191110610962, "val_acc": 0.755}, {"epoch": 22, "train_loss": 0.4185711395740509, "val_loss": 0.5084364175796509, "val_acc": 0.775}, {"epoch": 23, "train_loss": 0.42288042783737184, "val_loss": 0.4917571520805359, "val_acc": 0.76}, {"epoch": 24, "train_loss": 0.4216306734085083, "val_loss": 0.4927514278888702, "val_acc": 0.775}, {"epoch": 25, "train_loss": 0.4291934835910797, "val_loss": 0.49987715125083926, "val_acc": 0.775}], "final_metrics": {"epoch": 25, "train_loss": 0.4291934835910797, "val_loss": 0.49987715125083926, "val_acc": 0.775}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, 3))", "history": [{"epoch": 1, "train_loss": 0.9843513011932373, "val_loss": 0.9047394967079163, "val_acc": 0.58}, {"epoch": 2, "train_loss": 0.8216707110404968, "val_loss": 0.7304354548454285, "val_acc": 0.615}, {"epoch": 3, "train_loss": 0.644498143196106, "val_loss": 0.5736521720886231, "val_acc": 0.765}, {"epoch": 4, "train_loss": 0.5265160298347473, "val_loss": 0.48795778274536133, "val_acc": 0.8}, {"epoch": 5, "train_loss": 0.4809634304046631, "val_loss": 0.485700216293335, "val_acc": 0.77}, {"epoch": 6, "train_loss": 0.47356014132499696, "val_loss": 0.43869666576385496, "val_acc": 0.84}, {"epoch": 7, "train_loss": 0.46164268255233765, "val_loss": 0.4357795214653015, "val_acc": 0.795}, {"epoch": 8, "train_loss": 0.46565366148948667, "val_loss": 0.5257364082336425, "val_acc": 0.77}, {"epoch": 9, "train_loss": 0.4681847643852234, "val_loss": 0.4632417726516724, "val_acc": 0.805}, {"epoch": 10, "train_loss": 0.44565892457962036, "val_loss": 0.4130148732662201, "val_acc": 0.79}, {"epoch": 11, "train_loss": 0.4438547670841217, "val_loss": 0.42187091827392575, "val_acc": 0.825}, {"epoch": 12, "train_loss": 0.4481248068809509, "val_loss": 0.41947678565979, "val_acc": 0.82}, {"epoch": 13, "train_loss": 0.44476788997650146, "val_loss": 0.4160110902786255, "val_acc": 0.82}, {"epoch": 14, "train_loss": 0.45466936826705934, "val_loss": 0.4393052566051483, "val_acc": 0.785}, {"epoch": 15, "train_loss": 0.4417376351356506, "val_loss": 0.4201365077495575, "val_acc": 0.805}, {"epoch": 16, "train_loss": 0.43338008642196657, "val_loss": 0.42957635164260866, "val_acc": 0.825}, {"epoch": 17, "train_loss": 0.42896307706832887, "val_loss": 0.44648670077323915, "val_acc": 0.8}, {"epoch": 18, "train_loss": 0.44044565558433535, "val_loss": 0.43951432466506957, "val_acc": 0.79}, {"epoch": 19, "train_loss": 0.45230750799179076, "val_loss": 0.4247144865989685, "val_acc": 0.79}, {"epoch": 20, "train_loss": 0.4673351335525513, "val_loss": 0.5026200127601623, "val_acc": 0.745}, {"epoch": 21, "train_loss": 0.4921862268447876, "val_loss": 0.41918158531188965, "val_acc": 0.82}, {"epoch": 22, "train_loss": 0.45764703273773194, "val_loss": 0.47118751287460325, "val_acc": 0.785}, {"epoch": 23, "train_loss": 0.4542748785018921, "val_loss": 0.4330461525917053, "val_acc": 0.81}, {"epoch": 24, "train_loss": 0.42691744565963746, "val_loss": 0.4137323522567749, "val_acc": 0.805}, {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}], "final_metrics": {"epoch": 25, "train_loss": 0.4377139639854431, "val_loss": 0.4063666546344757, "val_acc": 0.82}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 48), nn.ReLU(), nn.Linear(48, 24), nn.ReLU(), nn.Linear(24, 3))", "history": [{"epoch": 1, "train_loss": 1.0331732249259948, "val_loss": 0.9443162059783936, "val_acc": 0.525}, {"epoch": 2, "train_loss": 0.867948682308197, "val_loss": 0.7564259314537048, "val_acc": 0.72}, {"epoch": 3, "train_loss": 0.6725446534156799, "val_loss": 0.552422034740448, "val_acc": 0.8}, {"epoch": 4, "train_loss": 0.5327745938301086, "val_loss": 0.44137310147285463, "val_acc": 0.835}, {"epoch": 5, "train_loss": 0.4957656478881836, "val_loss": 0.3921108460426331, "val_acc": 0.84}, {"epoch": 6, "train_loss": 0.48502216100692747, "val_loss": 0.39756796360015867, "val_acc": 0.86}, {"epoch": 7, "train_loss": 0.4773188877105713, "val_loss": 0.5084917306900024, "val_acc": 0.825}, {"epoch": 8, "train_loss": 0.4889907217025757, "val_loss": 0.4107833778858185, "val_acc": 0.825}, {"epoch": 9, "train_loss": 0.463825523853302, "val_loss": 0.39581693410873414, "val_acc": 0.865}, {"epoch": 10, "train_loss": 0.45649682760238647, "val_loss": 0.38396056175231935, "val_acc": 0.865}, {"epoch": 11, "train_loss": 0.4473332142829895, "val_loss": 0.3613078808784485, "val_acc": 0.84}, {"epoch": 12, "train_loss": 0.451347895860672, "val_loss": 0.35709758043289186, "val_acc": 0.86}, {"epoch": 13, "train_loss": 0.4463330614566803, "val_loss": 0.36405399441719055, "val_acc": 0.84}, {"epoch": 14, "train_loss": 0.4614866602420807, "val_loss": 0.38881322622299197, "val_acc": 0.845}, {"epoch": 15, "train_loss": 0.4587574207782745, "val_loss": 0.3870158803462982, "val_acc": 0.845}, {"epoch": 16, "train_loss": 0.47944381952285764, "val_loss": 0.3831759709119797, "val_acc": 0.825}, {"epoch": 17, "train_loss": 0.46759371042251585, "val_loss": 0.35558160305023195, "val_acc": 0.84}, {"epoch": 18, "train_loss": 0.441222847700119, "val_loss": 0.3923151183128357, "val_acc": 0.84}, {"epoch": 19, "train_loss": 0.4429554975032806, "val_loss": 0.38668938517570495, "val_acc": 0.83}, {"epoch": 20, "train_loss": 0.45185367345809935, "val_loss": 0.39916716814041137, "val_acc": 0.85}, {"epoch": 21, "train_loss": 0.45739450931549075, "val_loss": 0.35392323732376096, "val_acc": 0.85}, {"epoch": 22, "train_loss": 0.4425439763069153, "val_loss": 0.37757555484771727, "val_acc": 0.845}, {"epoch": 23, "train_loss": 0.435533047914505, "val_loss": 0.41575494050979617, "val_acc": 0.845}, {"epoch": 24, "train_loss": 0.4606682348251343, "val_loss": 0.4508614671230316, "val_acc": 0.82}, {"epoch": 25, "train_loss": 0.4814710247516632, "val_loss": 0.39321701049804686, "val_acc": 0.86}], "final_metrics": {"epoch": 25, "train_loss": 0.4814710247516632, "val_loss": 0.39321701049804686, "val_acc": 0.86}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 48), nn.ReLU(), nn.Linear(48, 36), nn.ReLU(), nn.Linear(36, 3))", "history": [{"epoch": 1, "train_loss": 0.9872208881378174, "val_loss": 0.831321291923523, "val_acc": 0.73}, {"epoch": 2, "train_loss": 0.6986266469955444, "val_loss": 0.564135286808014, "val_acc": 0.74}, {"epoch": 3, "train_loss": 0.515192643404007, "val_loss": 0.41384933233261106, "val_acc": 0.855}, {"epoch": 4, "train_loss": 0.47379114508628845, "val_loss": 0.3894459283351898, "val_acc": 0.85}, {"epoch": 5, "train_loss": 0.46878045320510864, "val_loss": 0.3767884659767151, "val_acc": 0.86}, {"epoch": 6, "train_loss": 0.45849798440933226, "val_loss": 0.3776595211029053, "val_acc": 0.85}, {"epoch": 7, "train_loss": 0.4657587718963623, "val_loss": 0.41562030553817747, "val_acc": 0.855}, {"epoch": 8, "train_loss": 0.5422514700889587, "val_loss": 0.6104249000549317, "val_acc": 0.725}, {"epoch": 9, "train_loss": 0.5550719344615936, "val_loss": 0.40562929391860963, "val_acc": 0.845}, {"epoch": 10, "train_loss": 0.49316105246543884, "val_loss": 0.38587780833244323, "val_acc": 0.865}, {"epoch": 11, "train_loss": 0.45426058769226074, "val_loss": 0.3829725134372711, "val_acc": 0.84}, {"epoch": 12, "train_loss": 0.4424034011363983, "val_loss": 0.3853782844543457, "val_acc": 0.88}, {"epoch": 13, "train_loss": 0.4525835645198822, "val_loss": 0.3937041735649109, "val_acc": 0.83}, {"epoch": 14, "train_loss": 0.44320823431015016, "val_loss": 0.3688957190513611, "val_acc": 0.87}, {"epoch": 15, "train_loss": 0.4361563384532928, "val_loss": 0.36699107885360716, "val_acc": 0.855}, {"epoch": 16, "train_loss": 0.4417396128177643, "val_loss": 0.3694485735893249, "val_acc": 0.87}, {"epoch": 17, "train_loss": 0.43770457863807677, "val_loss": 0.3657530784606934, "val_acc": 0.87}, {"epoch": 18, "train_loss": 0.45214008569717407, "val_loss": 0.3791801881790161, "val_acc": 0.855}, {"epoch": 19, "train_loss": 0.45583697080612184, "val_loss": 0.3799651634693146, "val_acc": 0.855}, {"epoch": 20, "train_loss": 0.4424219751358032, "val_loss": 0.3692040085792542, "val_acc": 0.88}, {"epoch": 21, "train_loss": 0.44021166205406187, "val_loss": 0.3906336259841919, "val_acc": 0.84}, {"epoch": 22, "train_loss": 0.4369510769844055, "val_loss": 0.37201473355293274, "val_acc": 0.87}, {"epoch": 23, "train_loss": 0.4407074224948883, "val_loss": 0.37785988569259643, "val_acc": 0.85}, {"epoch": 24, "train_loss": 0.43577964305877687, "val_loss": 0.3776939105987549, "val_acc": 0.88}, {"epoch": 25, "train_loss": 0.43879299640655517, "val_loss": 0.37006274223327634, "val_acc": 0.885}], "final_metrics": {"epoch": 25, "train_loss": 0.43879299640655517, "val_loss": 0.37006274223327634, "val_acc": 0.885}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(2, 64), nn.ReLU(), nn.Linear(64, 48), nn.ReLU(), nn.Linear(48, 3))", "history": [{"epoch": 1, "train_loss": 0.9439658379554748, "val_loss": 0.7013518381118774, "val_acc": 0.73}, {"epoch": 2, "train_loss": 0.6109218263626098, "val_loss": 0.5131269466876983, "val_acc": 0.755}, {"epoch": 3, "train_loss": 0.5351343739032746, "val_loss": 0.3637237048149109, "val_acc": 0.835}, {"epoch": 4, "train_loss": 0.5204328560829162, "val_loss": 0.3834173008799553, "val_acc": 0.87}, {"epoch": 5, "train_loss": 0.5213903319835663, "val_loss": 0.3792804580926895, "val_acc": 0.83}, {"epoch": 6, "train_loss": 0.472052538394928, "val_loss": 0.3601029706001282, "val_acc": 0.865}, {"epoch": 7, "train_loss": 0.46761040806770326, "val_loss": 0.3621868860721588, "val_acc": 0.865}, {"epoch": 8, "train_loss": 0.4718921113014221, "val_loss": 0.3737300902605057, "val_acc": 0.835}, {"epoch": 9, "train_loss": 0.47276705980300904, "val_loss": 0.360412395298481, "val_acc": 0.845}, {"epoch": 10, "train_loss": 0.4705814003944397, "val_loss": 0.38433645606040956, "val_acc": 0.855}, {"epoch": 11, "train_loss": 0.45168742775917053, "val_loss": 0.35841244041919706, "val_acc": 0.865}, {"epoch": 12, "train_loss": 0.46266516447067263, "val_loss": 0.3554943543672562, "val_acc": 0.855}, {"epoch": 13, "train_loss": 0.4622222065925598, "val_loss": 0.3431089973449707, "val_acc": 0.875}, {"epoch": 14, "train_loss": 0.45896952867507934, "val_loss": 0.40420363247394564, "val_acc": 0.815}, {"epoch": 15, "train_loss": 0.46801217794418337, "val_loss": 0.3580989527702332, "val_acc": 0.835}, {"epoch": 16, "train_loss": 0.46184300899505615, "val_loss": 0.35994656801223757, "val_acc": 0.865}, {"epoch": 17, "train_loss": 0.47049423277378083, "val_loss": 0.3565095922350883, "val_acc": 0.865}, {"epoch": 18, "train_loss": 0.46431282520294187, "val_loss": 0.39464322924613954, "val_acc": 0.82}, {"epoch": 19, "train_loss": 0.48560317516326906, "val_loss": 0.3694604027271271, "val_acc": 0.855}, {"epoch": 20, "train_loss": 0.4417827093601227, "val_loss": 0.35455340921878814, "val_acc": 0.855}, {"epoch": 21, "train_loss": 0.45112436890602114, "val_loss": 0.3422699576616287, "val_acc": 0.845}, {"epoch": 22, "train_loss": 0.445994873046875, "val_loss": 0.3708506888151169, "val_acc": 0.865}, {"epoch": 23, "train_loss": 0.44838969111442567, "val_loss": 0.36950834274291994, "val_acc": 0.82}, {"epoch": 24, "train_loss": 0.4646140027046204, "val_loss": 0.3595154356956482, "val_acc": 0.865}, {"epoch": 25, "train_loss": 0.44792795419692993, "val_loss": 0.3501656138896942, "val_acc": 0.845}], "final_metrics": {"epoch": 25, "train_loss": 0.44792795419692993, "val_loss": 0.3501656138896942, "val_acc": 0.845}}

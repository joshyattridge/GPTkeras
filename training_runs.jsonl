{"generated_layers": "self.layers = nn.Sequential(nn.Linear(13, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 3))\nself.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\nself.training_epochs = 100", "history": [{"epoch": 1, "train_loss": 1.0939780675189597, "val_loss": 1.0146013498306274, "val_acc": 0.6111111111111112}, {"epoch": 2, "train_loss": 1.056941440407659, "val_loss": 0.9905831217765808, "val_acc": 0.6111111111111112}, {"epoch": 3, "train_loss": 1.0226042807941707, "val_loss": 0.9662241339683533, "val_acc": 0.8055555555555556}, {"epoch": 4, "train_loss": 0.9887686623653895, "val_loss": 0.9402081370353699, "val_acc": 0.8055555555555556}, {"epoch": 5, "train_loss": 0.9533842499826995, "val_loss": 0.910409688949585, "val_acc": 0.9444444444444444}, {"epoch": 6, "train_loss": 0.916043545998318, "val_loss": 0.8779173493385315, "val_acc": 0.9722222222222222}, {"epoch": 7, "train_loss": 0.8761759585058185, "val_loss": 0.8428288698196411, "val_acc": 0.9444444444444444}, {"epoch": 8, "train_loss": 0.8335368305864469, "val_loss": 0.8043643236160278, "val_acc": 0.9444444444444444}, {"epoch": 9, "train_loss": 0.7881974258892973, "val_loss": 0.7635188698768616, "val_acc": 0.9444444444444444}, {"epoch": 10, "train_loss": 0.7404599886544994, "val_loss": 0.7206260561943054, "val_acc": 0.9722222222222222}, {"epoch": 11, "train_loss": 0.691836138006667, "val_loss": 0.6758139133453369, "val_acc": 0.9722222222222222}, {"epoch": 12, "train_loss": 0.6412679435501636, "val_loss": 0.6306661367416382, "val_acc": 0.9722222222222222}, {"epoch": 13, "train_loss": 0.5911839428082318, "val_loss": 0.5847381949424744, "val_acc": 0.9722222222222222}, {"epoch": 14, "train_loss": 0.5420520389583748, "val_loss": 0.5378605723381042, "val_acc": 0.9722222222222222}, {"epoch": 15, "train_loss": 0.4943346700198214, "val_loss": 0.49137020111083984, "val_acc": 0.9722222222222222}, {"epoch": 16, "train_loss": 0.44856937460496393, "val_loss": 0.44713136553764343, "val_acc": 0.9722222222222222}, {"epoch": 17, "train_loss": 0.4060742049150064, "val_loss": 0.4066244065761566, "val_acc": 0.9722222222222222}, {"epoch": 18, "train_loss": 0.36681068489249324, "val_loss": 0.36975330114364624, "val_acc": 0.9722222222222222}, {"epoch": 19, "train_loss": 0.33187198219165, "val_loss": 0.3348027467727661, "val_acc": 0.9722222222222222}, {"epoch": 20, "train_loss": 0.29964466980645355, "val_loss": 0.30092939734458923, "val_acc": 0.9722222222222222}, {"epoch": 21, "train_loss": 0.2715753736630292, "val_loss": 0.2687360644340515, "val_acc": 1.0}, {"epoch": 22, "train_loss": 0.2456931366886891, "val_loss": 0.2394702136516571, "val_acc": 1.0}, {"epoch": 23, "train_loss": 0.22246693914205257, "val_loss": 0.21278832852840424, "val_acc": 1.0}, {"epoch": 24, "train_loss": 0.20246737544805232, "val_loss": 0.1887001097202301, "val_acc": 1.0}, {"epoch": 25, "train_loss": 0.1838216502481783, "val_loss": 0.16675984859466553, "val_acc": 1.0}, {"epoch": 26, "train_loss": 0.1686553622425442, "val_loss": 0.1463594287633896, "val_acc": 1.0}, {"epoch": 27, "train_loss": 0.1535298960729384, "val_loss": 0.12962347269058228, "val_acc": 1.0}, {"epoch": 28, "train_loss": 0.14074704617681638, "val_loss": 0.11567237973213196, "val_acc": 1.0}, {"epoch": 29, "train_loss": 0.12922744536903544, "val_loss": 0.10345092415809631, "val_acc": 1.0}, {"epoch": 30, "train_loss": 0.11979633559223632, "val_loss": 0.09322812408208847, "val_acc": 1.0}, {"epoch": 31, "train_loss": 0.11005962944366562, "val_loss": 0.0848982110619545, "val_acc": 1.0}, {"epoch": 32, "train_loss": 0.10186659051498896, "val_loss": 0.07794257253408432, "val_acc": 1.0}, {"epoch": 33, "train_loss": 0.09472943737473287, "val_loss": 0.07197674363851547, "val_acc": 1.0}, {"epoch": 34, "train_loss": 0.08844994743105392, "val_loss": 0.06664876639842987, "val_acc": 1.0}, {"epoch": 35, "train_loss": 0.08255143064848135, "val_loss": 0.06190066784620285, "val_acc": 1.0}, {"epoch": 36, "train_loss": 0.07727751796933967, "val_loss": 0.0573163703083992, "val_acc": 1.0}, {"epoch": 37, "train_loss": 0.07240216287089066, "val_loss": 0.053231820464134216, "val_acc": 1.0}, {"epoch": 38, "train_loss": 0.0677142068219017, "val_loss": 0.049593087285757065, "val_acc": 1.0}, {"epoch": 39, "train_loss": 0.06377316035435233, "val_loss": 0.046271756291389465, "val_acc": 1.0}, {"epoch": 40, "train_loss": 0.05997801057889428, "val_loss": 0.04326178506016731, "val_acc": 1.0}, {"epoch": 41, "train_loss": 0.05664966066538448, "val_loss": 0.04052360728383064, "val_acc": 1.0}, {"epoch": 42, "train_loss": 0.05327647126896281, "val_loss": 0.038189955055713654, "val_acc": 1.0}, {"epoch": 43, "train_loss": 0.05049679737905381, "val_loss": 0.03604898974299431, "val_acc": 1.0}, {"epoch": 44, "train_loss": 0.04776233206437507, "val_loss": 0.03400985151529312, "val_acc": 1.0}, {"epoch": 45, "train_loss": 0.04547846516672994, "val_loss": 0.03209998086094856, "val_acc": 1.0}, {"epoch": 46, "train_loss": 0.04309834812728452, "val_loss": 0.030380044132471085, "val_acc": 1.0}, {"epoch": 47, "train_loss": 0.0410044654469255, "val_loss": 0.02884385734796524, "val_acc": 1.0}, {"epoch": 48, "train_loss": 0.03901049725606408, "val_loss": 0.027409600093960762, "val_acc": 1.0}, {"epoch": 49, "train_loss": 0.037007992483780415, "val_loss": 0.026042303070425987, "val_acc": 1.0}, {"epoch": 50, "train_loss": 0.03551187728282432, "val_loss": 0.024760281667113304, "val_acc": 1.0}, {"epoch": 51, "train_loss": 0.03379162825958829, "val_loss": 0.02347339503467083, "val_acc": 1.0}, {"epoch": 52, "train_loss": 0.0325225835639826, "val_loss": 0.022238485515117645, "val_acc": 1.0}, {"epoch": 53, "train_loss": 0.03106896524173273, "val_loss": 0.021154936403036118, "val_acc": 1.0}, {"epoch": 54, "train_loss": 0.02993755365236544, "val_loss": 0.020182736217975616, "val_acc": 1.0}, {"epoch": 55, "train_loss": 0.028589985674430787, "val_loss": 0.019414769485592842, "val_acc": 1.0}, {"epoch": 56, "train_loss": 0.027532031733385275, "val_loss": 0.018750131130218506, "val_acc": 1.0}, {"epoch": 57, "train_loss": 0.026372619970163828, "val_loss": 0.01823059469461441, "val_acc": 1.0}, {"epoch": 58, "train_loss": 0.025276736382552435, "val_loss": 0.017741352319717407, "val_acc": 1.0}, {"epoch": 59, "train_loss": 0.024303306523762957, "val_loss": 0.017307598143815994, "val_acc": 1.0}, {"epoch": 60, "train_loss": 0.023533044059918275, "val_loss": 0.01695500686764717, "val_acc": 1.0}, {"epoch": 61, "train_loss": 0.022785610230770748, "val_loss": 0.01661745458841324, "val_acc": 1.0}, {"epoch": 62, "train_loss": 0.022091859663036506, "val_loss": 0.01624153181910515, "val_acc": 1.0}, {"epoch": 63, "train_loss": 0.021369915652338048, "val_loss": 0.015905583277344704, "val_acc": 1.0}, {"epoch": 64, "train_loss": 0.020532487557125344, "val_loss": 0.015507648698985577, "val_acc": 1.0}, {"epoch": 65, "train_loss": 0.019817083496862734, "val_loss": 0.015095125883817673, "val_acc": 1.0}, {"epoch": 66, "train_loss": 0.019173698847405087, "val_loss": 0.014685637317597866, "val_acc": 1.0}, {"epoch": 67, "train_loss": 0.018505700968835557, "val_loss": 0.014324825257062912, "val_acc": 1.0}, {"epoch": 68, "train_loss": 0.01786831246925072, "val_loss": 0.013943438418209553, "val_acc": 1.0}, {"epoch": 69, "train_loss": 0.01722200676588945, "val_loss": 0.013577687554061413, "val_acc": 1.0}, {"epoch": 70, "train_loss": 0.01666896707627555, "val_loss": 0.013172175735235214, "val_acc": 1.0}, {"epoch": 71, "train_loss": 0.016190567617894898, "val_loss": 0.01276085153222084, "val_acc": 1.0}, {"epoch": 72, "train_loss": 0.015598776868321526, "val_loss": 0.01239951141178608, "val_acc": 1.0}, {"epoch": 73, "train_loss": 0.015090023508479058, "val_loss": 0.012165057472884655, "val_acc": 1.0}, {"epoch": 74, "train_loss": 0.014633039484771205, "val_loss": 0.012065849266946316, "val_acc": 1.0}, {"epoch": 75, "train_loss": 0.014188106053731811, "val_loss": 0.011921563185751438, "val_acc": 1.0}, {"epoch": 76, "train_loss": 0.013742811912277214, "val_loss": 0.011747078038752079, "val_acc": 1.0}, {"epoch": 77, "train_loss": 0.013398060470189847, "val_loss": 0.01152428612112999, "val_acc": 1.0}, {"epoch": 78, "train_loss": 0.012966618892854788, "val_loss": 0.011283657513558865, "val_acc": 1.0}, {"epoch": 79, "train_loss": 0.01250096558737503, "val_loss": 0.011026842519640923, "val_acc": 1.0}, {"epoch": 80, "train_loss": 0.012111732290244438, "val_loss": 0.010788685642182827, "val_acc": 1.0}, {"epoch": 81, "train_loss": 0.011777942167253981, "val_loss": 0.01060566771775484, "val_acc": 1.0}, {"epoch": 82, "train_loss": 0.011339053124661597, "val_loss": 0.010453884489834309, "val_acc": 1.0}, {"epoch": 83, "train_loss": 0.010999932609708376, "val_loss": 0.0102462787181139, "val_acc": 1.0}, {"epoch": 84, "train_loss": 0.010702029159161406, "val_loss": 0.010028746910393238, "val_acc": 1.0}, {"epoch": 85, "train_loss": 0.010383013504701602, "val_loss": 0.00981895998120308, "val_acc": 1.0}, {"epoch": 86, "train_loss": 0.01024047238096385, "val_loss": 0.00965605117380619, "val_acc": 1.0}, {"epoch": 87, "train_loss": 0.009838417802058476, "val_loss": 0.009533911943435669, "val_acc": 1.0}, {"epoch": 88, "train_loss": 0.00948915174099761, "val_loss": 0.009431990794837475, "val_acc": 1.0}, {"epoch": 89, "train_loss": 0.009310258316322111, "val_loss": 0.009339217096567154, "val_acc": 1.0}, {"epoch": 90, "train_loss": 0.009001821941945334, "val_loss": 0.009208787232637405, "val_acc": 1.0}, {"epoch": 91, "train_loss": 0.008755254073881768, "val_loss": 0.009067332372069359, "val_acc": 1.0}, {"epoch": 92, "train_loss": 0.008475134936226925, "val_loss": 0.008909630589187145, "val_acc": 1.0}, {"epoch": 93, "train_loss": 0.008251563409789347, "val_loss": 0.008778144605457783, "val_acc": 1.0}, {"epoch": 94, "train_loss": 0.008009556792414104, "val_loss": 0.00862859282642603, "val_acc": 1.0}, {"epoch": 95, "train_loss": 0.007803749817777687, "val_loss": 0.008490482345223427, "val_acc": 1.0}, {"epoch": 96, "train_loss": 0.007661953227410854, "val_loss": 0.008380923420190811, "val_acc": 1.0}, {"epoch": 97, "train_loss": 0.0074887461386437355, "val_loss": 0.008257005363702774, "val_acc": 1.0}, {"epoch": 98, "train_loss": 0.007265235710574288, "val_loss": 0.008139226585626602, "val_acc": 1.0}, {"epoch": 99, "train_loss": 0.00706457492278915, "val_loss": 0.008016662672162056, "val_acc": 1.0}, {"epoch": 100, "train_loss": 0.006796266096578517, "val_loss": 0.00796310231089592, "val_acc": 1.0}], "final_metrics": {"epoch": 100, "train_loss": 0.006796266096578517, "val_loss": 0.00796310231089592, "val_acc": 1.0}}
{"generated_layers": "self.layers = nn.Sequential(nn.Linear(13, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 3))\nself.optimizer = torch.optim.Adam(self.parameters(), lr=0.0005)\nself.training_epochs = 150", "history": [{"epoch": 1, "train_loss": 1.0307064056396484, "val_loss": 1.0342391729354858, "val_acc": 0.5555555555555556}, {"epoch": 2, "train_loss": 0.976178164213476, "val_loss": 0.9871898293495178, "val_acc": 0.7222222222222222}, {"epoch": 3, "train_loss": 0.9253241134361482, "val_loss": 0.9446089267730713, "val_acc": 0.8333333333333334}, {"epoch": 4, "train_loss": 0.8758281947861255, "val_loss": 0.9024463295936584, "val_acc": 0.8611111111111112}, {"epoch": 5, "train_loss": 0.8278202783893531, "val_loss": 0.8585335612297058, "val_acc": 0.8888888888888888}, {"epoch": 6, "train_loss": 0.7805354821849877, "val_loss": 0.8153679370880127, "val_acc": 0.9166666666666666}, {"epoch": 7, "train_loss": 0.7326650804197284, "val_loss": 0.7735057473182678, "val_acc": 0.9166666666666666}, {"epoch": 8, "train_loss": 0.6852266133671076, "val_loss": 0.73481684923172, "val_acc": 0.9166666666666666}, {"epoch": 9, "train_loss": 0.6398699745325975, "val_loss": 0.6978275775909424, "val_acc": 0.8888888888888888}, {"epoch": 10, "train_loss": 0.5955174128774187, "val_loss": 0.6591736078262329, "val_acc": 0.8888888888888888}, {"epoch": 11, "train_loss": 0.5522661582684852, "val_loss": 0.6201011538505554, "val_acc": 0.8888888888888888}, {"epoch": 12, "train_loss": 0.5116123036599495, "val_loss": 0.5820638537406921, "val_acc": 0.8888888888888888}, {"epoch": 13, "train_loss": 0.4735383769156228, "val_loss": 0.5422631502151489, "val_acc": 0.8888888888888888}, {"epoch": 14, "train_loss": 0.43680620781132873, "val_loss": 0.5013568997383118, "val_acc": 0.9166666666666666}, {"epoch": 15, "train_loss": 0.40232479824146755, "val_loss": 0.4610588252544403, "val_acc": 0.9444444444444444}, {"epoch": 16, "train_loss": 0.3710705812128497, "val_loss": 0.4214544892311096, "val_acc": 0.9722222222222222}, {"epoch": 17, "train_loss": 0.34072145273987675, "val_loss": 0.38533103466033936, "val_acc": 0.9722222222222222}, {"epoch": 18, "train_loss": 0.31346819434367434, "val_loss": 0.3507102131843567, "val_acc": 1.0}, {"epoch": 19, "train_loss": 0.2879311352128714, "val_loss": 0.31886598467826843, "val_acc": 1.0}, {"epoch": 20, "train_loss": 0.2652555093379088, "val_loss": 0.29006239771842957, "val_acc": 1.0}, {"epoch": 21, "train_loss": 0.24356549999243776, "val_loss": 0.2647084891796112, "val_acc": 1.0}, {"epoch": 22, "train_loss": 0.22446882682786862, "val_loss": 0.24099329113960266, "val_acc": 1.0}, {"epoch": 23, "train_loss": 0.20738349183344504, "val_loss": 0.21947549283504486, "val_acc": 1.0}, {"epoch": 24, "train_loss": 0.19170630523856258, "val_loss": 0.20138421654701233, "val_acc": 1.0}, {"epoch": 25, "train_loss": 0.1778161070296462, "val_loss": 0.18580864369869232, "val_acc": 1.0}, {"epoch": 26, "train_loss": 0.16523357113482248, "val_loss": 0.17080561816692352, "val_acc": 1.0}, {"epoch": 27, "train_loss": 0.15367328511997008, "val_loss": 0.15669582784175873, "val_acc": 1.0}, {"epoch": 28, "train_loss": 0.14292193739347056, "val_loss": 0.143419548869133, "val_acc": 1.0}, {"epoch": 29, "train_loss": 0.1331074625043802, "val_loss": 0.13149993121623993, "val_acc": 1.0}, {"epoch": 30, "train_loss": 0.1242266478882709, "val_loss": 0.12077251821756363, "val_acc": 1.0}, {"epoch": 31, "train_loss": 0.11655076446247772, "val_loss": 0.11185559630393982, "val_acc": 1.0}, {"epoch": 32, "train_loss": 0.10952073514041766, "val_loss": 0.10428845882415771, "val_acc": 1.0}, {"epoch": 33, "train_loss": 0.10345492963220032, "val_loss": 0.09734208136796951, "val_acc": 1.0}, {"epoch": 34, "train_loss": 0.09799216582741536, "val_loss": 0.09100706875324249, "val_acc": 1.0}, {"epoch": 35, "train_loss": 0.09255281562956286, "val_loss": 0.08479852229356766, "val_acc": 1.0}, {"epoch": 36, "train_loss": 0.08737024045746092, "val_loss": 0.07889603823423386, "val_acc": 1.0}, {"epoch": 37, "train_loss": 0.08333853348879747, "val_loss": 0.07377448678016663, "val_acc": 1.0}, {"epoch": 38, "train_loss": 0.07878523246503212, "val_loss": 0.06961104273796082, "val_acc": 1.0}, {"epoch": 39, "train_loss": 0.07478036295989869, "val_loss": 0.06609176844358444, "val_acc": 1.0}, {"epoch": 40, "train_loss": 0.07128221599358908, "val_loss": 0.06281419843435287, "val_acc": 1.0}, {"epoch": 41, "train_loss": 0.06770745738291405, "val_loss": 0.05987062677741051, "val_acc": 1.0}, {"epoch": 42, "train_loss": 0.0648407213599749, "val_loss": 0.05715205892920494, "val_acc": 1.0}, {"epoch": 43, "train_loss": 0.06220478826845196, "val_loss": 0.054713211953639984, "val_acc": 1.0}, {"epoch": 44, "train_loss": 0.05933425155743747, "val_loss": 0.05214202031493187, "val_acc": 1.0}, {"epoch": 45, "train_loss": 0.05669843059190562, "val_loss": 0.049684181809425354, "val_acc": 1.0}, {"epoch": 46, "train_loss": 0.05446866325194567, "val_loss": 0.04757780209183693, "val_acc": 1.0}, {"epoch": 47, "train_loss": 0.05219647891714539, "val_loss": 0.04556600749492645, "val_acc": 1.0}, {"epoch": 48, "train_loss": 0.050014954742411494, "val_loss": 0.04368056729435921, "val_acc": 1.0}, {"epoch": 49, "train_loss": 0.04768129448655625, "val_loss": 0.04201032593846321, "val_acc": 1.0}, {"epoch": 50, "train_loss": 0.045674449960950395, "val_loss": 0.040471822023391724, "val_acc": 1.0}, {"epoch": 51, "train_loss": 0.04357080611492127, "val_loss": 0.039115943014621735, "val_acc": 1.0}, {"epoch": 52, "train_loss": 0.04190731691327733, "val_loss": 0.03789325803518295, "val_acc": 1.0}, {"epoch": 53, "train_loss": 0.040395709620395175, "val_loss": 0.036619290709495544, "val_acc": 1.0}, {"epoch": 54, "train_loss": 0.03893151299529512, "val_loss": 0.03534790128469467, "val_acc": 1.0}, {"epoch": 55, "train_loss": 0.037677683880631356, "val_loss": 0.03409900143742561, "val_acc": 1.0}, {"epoch": 56, "train_loss": 0.03624524244330299, "val_loss": 0.032726891338825226, "val_acc": 1.0}, {"epoch": 57, "train_loss": 0.034995639513076195, "val_loss": 0.03144088387489319, "val_acc": 1.0}, {"epoch": 58, "train_loss": 0.03375637339769115, "val_loss": 0.03022344596683979, "val_acc": 1.0}, {"epoch": 59, "train_loss": 0.03270167002165821, "val_loss": 0.029106544330716133, "val_acc": 1.0}, {"epoch": 60, "train_loss": 0.03157037900577129, "val_loss": 0.02819136530160904, "val_acc": 1.0}, {"epoch": 61, "train_loss": 0.030441378308853632, "val_loss": 0.02727741003036499, "val_acc": 1.0}, {"epoch": 62, "train_loss": 0.02947485583349013, "val_loss": 0.026405828073620796, "val_acc": 1.0}, {"epoch": 63, "train_loss": 0.02846840574917659, "val_loss": 0.025678372010588646, "val_acc": 1.0}, {"epoch": 64, "train_loss": 0.027993217202454384, "val_loss": 0.025019502267241478, "val_acc": 1.0}, {"epoch": 65, "train_loss": 0.02736135737472017, "val_loss": 0.024427132681012154, "val_acc": 1.0}, {"epoch": 66, "train_loss": 0.026610870229106555, "val_loss": 0.023861799389123917, "val_acc": 1.0}, {"epoch": 67, "train_loss": 0.02580496792117475, "val_loss": 0.023254672065377235, "val_acc": 1.0}, {"epoch": 68, "train_loss": 0.02496121212525267, "val_loss": 0.022723698988556862, "val_acc": 1.0}, {"epoch": 69, "train_loss": 0.024031727456710707, "val_loss": 0.0222410149872303, "val_acc": 1.0}, {"epoch": 70, "train_loss": 0.023067799055765212, "val_loss": 0.021785195916891098, "val_acc": 1.0}, {"epoch": 71, "train_loss": 0.02239497223685325, "val_loss": 0.02137863077223301, "val_acc": 1.0}, {"epoch": 72, "train_loss": 0.021569243592905327, "val_loss": 0.020880796015262604, "val_acc": 1.0}, {"epoch": 73, "train_loss": 0.020902984998595546, "val_loss": 0.02033591829240322, "val_acc": 1.0}, {"epoch": 74, "train_loss": 0.02024683807517441, "val_loss": 0.019808273762464523, "val_acc": 1.0}, {"epoch": 75, "train_loss": 0.019677250816578597, "val_loss": 0.01934969797730446, "val_acc": 1.0}, {"epoch": 76, "train_loss": 0.019093011086150795, "val_loss": 0.01886160857975483, "val_acc": 1.0}, {"epoch": 77, "train_loss": 0.01848413031154745, "val_loss": 0.018437460064888, "val_acc": 1.0}, {"epoch": 78, "train_loss": 0.017890830379976352, "val_loss": 0.018110044300556183, "val_acc": 1.0}, {"epoch": 79, "train_loss": 0.017525208117046828, "val_loss": 0.017944728955626488, "val_acc": 1.0}, {"epoch": 80, "train_loss": 0.01678060052890173, "val_loss": 0.01770005375146866, "val_acc": 1.0}, {"epoch": 81, "train_loss": 0.01653372270750328, "val_loss": 0.017535556107759476, "val_acc": 1.0}, {"epoch": 82, "train_loss": 0.016029541262648474, "val_loss": 0.01712779514491558, "val_acc": 1.0}, {"epoch": 83, "train_loss": 0.015615309909983, "val_loss": 0.016598563641309738, "val_acc": 1.0}, {"epoch": 84, "train_loss": 0.015068556405079196, "val_loss": 0.016169287264347076, "val_acc": 1.0}, {"epoch": 85, "train_loss": 0.01463836347553092, "val_loss": 0.015839405357837677, "val_acc": 1.0}, {"epoch": 86, "train_loss": 0.014251713982035577, "val_loss": 0.015509332530200481, "val_acc": 1.0}, {"epoch": 87, "train_loss": 0.013867412424895545, "val_loss": 0.015157110057771206, "val_acc": 1.0}, {"epoch": 88, "train_loss": 0.013482138540753176, "val_loss": 0.014807477593421936, "val_acc": 1.0}, {"epoch": 89, "train_loss": 0.013158682625557125, "val_loss": 0.014445389620959759, "val_acc": 1.0}, {"epoch": 90, "train_loss": 0.01285822640999522, "val_loss": 0.014091074466705322, "val_acc": 1.0}, {"epoch": 91, "train_loss": 0.012573264503169437, "val_loss": 0.013775037601590157, "val_acc": 1.0}, {"epoch": 92, "train_loss": 0.012263441786274944, "val_loss": 0.01349968183785677, "val_acc": 1.0}, {"epoch": 93, "train_loss": 0.012037984381633168, "val_loss": 0.013202706351876259, "val_acc": 1.0}, {"epoch": 94, "train_loss": 0.01178043330757236, "val_loss": 0.012950771488249302, "val_acc": 1.0}, {"epoch": 95, "train_loss": 0.011509699107501919, "val_loss": 0.012745014391839504, "val_acc": 1.0}, {"epoch": 96, "train_loss": 0.011271903042117474, "val_loss": 0.012569078244268894, "val_acc": 1.0}, {"epoch": 97, "train_loss": 0.011010904029064196, "val_loss": 0.012391903437674046, "val_acc": 1.0}, {"epoch": 98, "train_loss": 0.010797134653048617, "val_loss": 0.012241382151842117, "val_acc": 1.0}, {"epoch": 99, "train_loss": 0.010537966659528688, "val_loss": 0.012106506153941154, "val_acc": 1.0}, {"epoch": 100, "train_loss": 0.010341272781222639, "val_loss": 0.011967265047132969, "val_acc": 1.0}, {"epoch": 101, "train_loss": 0.010092634360082972, "val_loss": 0.011745654977858067, "val_acc": 1.0}, {"epoch": 102, "train_loss": 0.009863879751335358, "val_loss": 0.011550393886864185, "val_acc": 1.0}, {"epoch": 103, "train_loss": 0.009635603965365027, "val_loss": 0.011364559642970562, "val_acc": 1.0}, {"epoch": 104, "train_loss": 0.00945322531682085, "val_loss": 0.011192782782018185, "val_acc": 1.0}, {"epoch": 105, "train_loss": 0.00925479650589257, "val_loss": 0.011023377068340778, "val_acc": 1.0}, {"epoch": 106, "train_loss": 0.00905957143806236, "val_loss": 0.01091625913977623, "val_acc": 1.0}, {"epoch": 107, "train_loss": 0.00886249464844734, "val_loss": 0.010790851898491383, "val_acc": 1.0}, {"epoch": 108, "train_loss": 0.008684160666618968, "val_loss": 0.010709399357438087, "val_acc": 1.0}, {"epoch": 109, "train_loss": 0.00850617612751437, "val_loss": 0.010631377808749676, "val_acc": 1.0}, {"epoch": 110, "train_loss": 0.008310755783639533, "val_loss": 0.010465215891599655, "val_acc": 1.0}, {"epoch": 111, "train_loss": 0.008137487573549151, "val_loss": 0.010317526757717133, "val_acc": 1.0}, {"epoch": 112, "train_loss": 0.00798807336463475, "val_loss": 0.010176471434533596, "val_acc": 1.0}, {"epoch": 113, "train_loss": 0.007829510574032304, "val_loss": 0.010050513781607151, "val_acc": 1.0}, {"epoch": 114, "train_loss": 0.007656174725000287, "val_loss": 0.009902963414788246, "val_acc": 1.0}, {"epoch": 115, "train_loss": 0.007540287226963211, "val_loss": 0.009750068187713623, "val_acc": 1.0}, {"epoch": 116, "train_loss": 0.007294235278812932, "val_loss": 0.00972929410636425, "val_acc": 1.0}, {"epoch": 117, "train_loss": 0.007125161457019792, "val_loss": 0.009798265062272549, "val_acc": 1.0}, {"epoch": 118, "train_loss": 0.006998086912216435, "val_loss": 0.009811447001993656, "val_acc": 1.0}, {"epoch": 119, "train_loss": 0.006906818388633325, "val_loss": 0.009802698157727718, "val_acc": 1.0}, {"epoch": 120, "train_loss": 0.0068175258429747235, "val_loss": 0.009771686047315598, "val_acc": 1.0}, {"epoch": 121, "train_loss": 0.006675009766567341, "val_loss": 0.00965394452214241, "val_acc": 1.0}, {"epoch": 122, "train_loss": 0.0065298335443080315, "val_loss": 0.009504339657723904, "val_acc": 1.0}, {"epoch": 123, "train_loss": 0.006379241639466195, "val_loss": 0.009304022416472435, "val_acc": 1.0}, {"epoch": 124, "train_loss": 0.006193935182470251, "val_loss": 0.009120013564825058, "val_acc": 1.0}, {"epoch": 125, "train_loss": 0.006075843748912005, "val_loss": 0.008895790204405785, "val_acc": 1.0}, {"epoch": 126, "train_loss": 0.005941972890737611, "val_loss": 0.008723176084458828, "val_acc": 1.0}, {"epoch": 127, "train_loss": 0.005853232412769551, "val_loss": 0.008560949005186558, "val_acc": 1.0}, {"epoch": 128, "train_loss": 0.005739356883027604, "val_loss": 0.008423610590398312, "val_acc": 1.0}, {"epoch": 129, "train_loss": 0.0056406818723804516, "val_loss": 0.008276533335447311, "val_acc": 1.0}, {"epoch": 130, "train_loss": 0.005547941301647626, "val_loss": 0.008176948875188828, "val_acc": 1.0}, {"epoch": 131, "train_loss": 0.005438954818626524, "val_loss": 0.008093607611954212, "val_acc": 1.0}, {"epoch": 132, "train_loss": 0.005346839408009825, "val_loss": 0.008013572543859482, "val_acc": 1.0}, {"epoch": 133, "train_loss": 0.0052503552091058715, "val_loss": 0.007916141301393509, "val_acc": 1.0}, {"epoch": 134, "train_loss": 0.005137309353326408, "val_loss": 0.00783239584416151, "val_acc": 1.0}, {"epoch": 135, "train_loss": 0.005047572099498775, "val_loss": 0.007793494500219822, "val_acc": 1.0}, {"epoch": 136, "train_loss": 0.0049522653071236026, "val_loss": 0.00776852760463953, "val_acc": 1.0}, {"epoch": 137, "train_loss": 0.004852935858726711, "val_loss": 0.007755887228995562, "val_acc": 1.0}, {"epoch": 138, "train_loss": 0.004774375136574389, "val_loss": 0.007719132583588362, "val_acc": 1.0}, {"epoch": 139, "train_loss": 0.0046828398218667, "val_loss": 0.007635013200342655, "val_acc": 1.0}, {"epoch": 140, "train_loss": 0.004613723643583206, "val_loss": 0.0075263031758368015, "val_acc": 1.0}, {"epoch": 141, "train_loss": 0.00453261458839644, "val_loss": 0.007445036433637142, "val_acc": 1.0}, {"epoch": 142, "train_loss": 0.004453700012855337, "val_loss": 0.007367332000285387, "val_acc": 1.0}, {"epoch": 143, "train_loss": 0.004389986149888014, "val_loss": 0.007295553106814623, "val_acc": 1.0}, {"epoch": 144, "train_loss": 0.004312310485877622, "val_loss": 0.007279431447386742, "val_acc": 1.0}, {"epoch": 145, "train_loss": 0.004249307905769789, "val_loss": 0.007298151031136513, "val_acc": 1.0}, {"epoch": 146, "train_loss": 0.004186431109957712, "val_loss": 0.007282463368028402, "val_acc": 1.0}, {"epoch": 147, "train_loss": 0.00411479858169988, "val_loss": 0.007233207579702139, "val_acc": 1.0}, {"epoch": 148, "train_loss": 0.0040526484060560315, "val_loss": 0.007182138040661812, "val_acc": 1.0}, {"epoch": 149, "train_loss": 0.003993707573743091, "val_loss": 0.0071351430378854275, "val_acc": 1.0}, {"epoch": 150, "train_loss": 0.003928368471720269, "val_loss": 0.007066888269037008, "val_acc": 1.0}], "final_metrics": {"epoch": 150, "train_loss": 0.003928368471720269, "val_loss": 0.007066888269037008, "val_acc": 1.0}}

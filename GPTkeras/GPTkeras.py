from __future__ import annotations

import argparse
import json
import os
import random
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Callable, Tuple

import numpy as np
import tensorflow as tf
from tensorflow import keras
from openai import OpenAI

DEFAULT_SEED = 42

class GPTkeras:
    def __init__(
        self,
        train_x,
        train_y,
        api_key: str | None = None,
        model: str = "gpt-4o-mini",
        history_path: str | os.PathLike[str] | None = "chat_history.jsonl",
        continue_from_history: bool = False,
        seed: int | None = DEFAULT_SEED,
    ):
        self.train_x = train_x
        self.train_y = train_y
        self.input_shape = tuple(train_x.shape[1:]) if train_x.ndim > 1 else (1,)
        if seed is not None and not isinstance(seed, (int, np.integer)):
            raise TypeError("seed must be an integer or None")
        self.seed = int(seed) if seed is not None else None
        if self.seed is not None:
            self._set_seed(self.seed)
        if np.issubdtype(train_y.dtype, np.integer):
            if train_y.ndim > 1 and train_y.shape[-1] > 1:
                self.num_classes = int(train_y.shape[-1])
            else:
                self.num_classes = int(train_y.max()) + 1
        else:
            self.num_classes = 1
        self.gpt_client = OpenAI(api_key=api_key)
        self.gpt_model = model
        self.training_config: dict[str, int] = {}
        self.best_model_path = Path("best_model.keras")
        self.best_model = None
        self.best_model_results = None
        self.callbacks_factory: Callable[[], list[keras.callbacks.Callback]] | None = None

    def _set_seed(self, seed: int) -> None:
        os.environ["PYTHONHASHSEED"] = str(seed)
        random.seed(seed)
        np.random.seed(seed)
        try:
            tf.keras.utils.set_random_seed(seed)
        except AttributeError:
            tf.random.set_seed(seed)
        else:
            tf.random.set_seed(seed)

    def chat(self, messages) -> str:
        print(messages)
        if self.gpt_client is None:
            raise ValueError("OpenAIChatClient instance is required to chat")
        completion = self.gpt_client.chat.completions.create(model=self.gpt_model, messages=messages)
        message = completion.choices[0].message
        response = message.get("content") if isinstance(message, dict) else getattr(message, "content", "")
        if not isinstance(response, str):
            response = "" if response is None else str(response)
        print(response)
        return response

    def build_model(self) -> keras.Model:
        if self.gpt_client is None:
            raise ValueError("OpenAIChatClient instance is required to build the model")

        self.callbacks_factory = None
        sample_size = min(5, len(self.train_x))
        sample_inputs = self.train_x[: min(sample_size, len(self.train_x))]
        sample_outputs = self.train_y[: min(sample_size, len(self.train_y))]
        prompt = self._build_prompt(sample_inputs=sample_inputs, sample_outputs=sample_outputs)

        response = self.chat([{"role": "user", "content": prompt}]).strip()
        if not response:
            raise RuntimeError("GPT did not return any model code")

        exec_globals = {
            "keras": keras,
            "tf": tf,
            "np": np,
            "Path": Path,
            "BEST_MODEL_PATH": str(self.best_model_path),
        }
        exec_locals: dict[str, object] = {}
        try:
            exec(response, exec_globals, exec_locals)
        except Exception as exc:
            raise RuntimeError("Failed to execute model code generated by GPT") from exc

        batch_size = exec_locals.get("BATCH_SIZE")
        epochs = exec_locals.get("EPOCHS")

        if not isinstance(batch_size, (int, np.integer)) or batch_size <= 0:
            raise ValueError("GPT response must define a positive integer BATCH_SIZE constant.")
        if not isinstance(epochs, (int, np.integer)) or epochs <= 0:
            raise ValueError("GPT response must define a positive integer EPOCHS constant.")

        self.training_config["batch_size"] = int(batch_size)
        self.training_config["epochs"] = int(epochs)

        create_model = exec_locals.get("create_model")
        if not callable(create_model):
            raise ValueError("GPT response did not define a callable create_model function")

        create_callbacks = exec_locals.get("create_callbacks")
        if create_callbacks is not None and not callable(create_callbacks):
            raise ValueError("create_callbacks must be callable when defined")
        if callable(create_callbacks):
            self.callbacks_factory = create_callbacks

        model = create_model()
        if not isinstance(model, keras.Model):
            raise TypeError("create_model must return a compiled keras.Model instance")

        return model, response

    def _summarize_array(self, array: np.ndarray, max_preview_values: int = 128) -> dict[str, object]:
        summary: dict[str, object] = {
            "dtype": str(array.dtype),
            "shape": list(array.shape),
            "size": int(array.size),
        }

        if array.size == 0:
            summary["sample_count"] = 0
            summary["sample_description"] = "Array is empty"
            summary["sample_values"] = []
            return summary

        is_numeric = np.issubdtype(array.dtype, np.number)

        if is_numeric:
            summary["min"] = float(np.min(array))
            summary["max"] = float(np.max(array))
            summary["mean"] = float(np.mean(array))
            summary["std"] = float(np.std(array))

        flat = array.reshape(-1)
        if flat.size <= max_preview_values:
            preview = flat
            summary["sample_description"] = f"All {flat.size} values"
        else:
            indices = np.linspace(0, flat.size - 1, num=max_preview_values, dtype=int)
            preview = flat[indices]
            summary["sample_description"] = f"Uniform preview of {max_preview_values} values from {flat.size}"

        if is_numeric:
            preview = np.round(preview.astype(np.float64), decimals=6)

        summary["sample_values"] = preview.tolist()
        summary["sample_count"] = len(summary["sample_values"])

        return summary

    def _build_prompt(self, sample_inputs: np.ndarray, sample_outputs: np.ndarray) -> str:
        input_shape = self.input_shape
        output_shape = tuple(sample_outputs.shape[1:]) if sample_outputs.ndim > 1 else ()
        task_type = "classification" if self.num_classes > 1 else "regression"
        inputs_summary = json.dumps(self._summarize_array(sample_inputs), indent=2)
        outputs_summary = json.dumps(self._summarize_array(sample_outputs), indent=2)

        prompt = f"""
You are an expert TensorFlow engineer. Generate Python source code for a function called create_model() that builds and compiles a tf.keras.Model for a {task_type} problem.
If you know of any previous models that you created and the results they produced then use this information to influence your design.
You can make small architectural or hyperparameter changes because you will have {self.max_iterations} opportunities to iterate; focus on steady improvements while guarding against overfitting or underfitting.
But make sure that you are showing steady improvements before you reach {self.max_iterations} iterations.

Project constraints:
- Training input shape: {input_shape}
- Training output shape: {output_shape if output_shape else 'scalar'}
- Number of target classes: {self.num_classes}
- Sample input summary: {inputs_summary}
- Sample target summary: {outputs_summary}
- The constant BEST_MODEL_PATH is available for saving checkpoints.

Requirements:
1. The function must be pure Python using tf.keras layers and return a compiled keras.Model instance.
2. Respond with raw Python code that defines create_model() and sets integer constants BATCH_SIZE and EPOCHS at module scope (outside create_model); do not include narrative text, comments outside of code, or any Markdown/backtick fences. The first non-empty line must start with either BATCH_SIZE or EPOCHS.
3. Ensure BATCH_SIZE and EPOCHS are positive integers tailored to the task and data size.
4. Design the network so every convolution, pooling, or downsampling step keeps all spatial dimensions at least 1 for the provided input shape; adjust kernel sizes, strides, or padding (e.g., prefer padding="same" when needed) to avoid invalid tensor shapes.
5. Always define a create_callbacks() function with no parameters that returns a list (or tuple) of tf.keras.callbacks.Callback instances including EarlyStopping and a learning-rate scheduler (e.g., ReduceLROnPlateau or LearningRateScheduler); keep learning rates from decaying to zero by setting a positive floor (e.g., `min_lr > 0` or a cosine schedule with a floor). Callbacks that write checkpoints must target BEST_MODEL_PATH and avoid other locations.
6. Keep the total number of trainable parameters reasonable for the dataset size; avoid unnecessarily large models.
7. Do not use Flatten layers on high-dimensional feature mapsâ€”prefer pooling or global pooling to reduce dimensionality before any flattening step.
8. Always include at least one form of regularisation such as Dropout, kernel/bias weight decay, or BatchNormalization layers.
9. Add input normalisation or rescaling layers that suit the data type so the model sees well-scaled inputs.
10. Ensure the final layer activation and compiled loss exactly match the task type (binary classification, multi-class classification, or regression).

Current Best Model:
{self.best_model if self.best_model is not None else 'No best model yet'}
Current Best Model Results:
{self.best_model_results if self.best_model_results is not None else 'N/A'}
"""
        return prompt.strip()

    def _build_callbacks(self) -> list[keras.callbacks.Callback]:
        if self.callbacks_factory is None:
            return []

        try:
            callbacks = self.callbacks_factory()
        except Exception as exc:
            raise RuntimeError("create_callbacks() raised an exception") from exc

        if callbacks is None:
            return []
        if not isinstance(callbacks, (list, tuple)):
            raise TypeError("create_callbacks must return a list or tuple of keras.callbacks.Callback instances")

        validated_callbacks: list[keras.callbacks.Callback] = []
        for callback in callbacks:
            if not isinstance(callback, keras.callbacks.Callback):
                raise TypeError("create_callbacks must return keras.callbacks.Callback instances")

            # Silence noisy checkpoint logging if the generated code enables it.
            if isinstance(callback, keras.callbacks.ModelCheckpoint) and getattr(callback, "verbose", 0) != 0:
                callback.verbose = 0
            validated_callbacks.append(callback)

        return validated_callbacks

    class SingleLineLogger(keras.callbacks.Callback):
        def __init__(self, model_iteration: int = 0):
            super().__init__()
            self.model_iteration = model_iteration

        def on_train_begin(self, logs=None):
            # Print model summary before training starts
            if hasattr(self, 'model') and self.model is not None:
                self.model.summary()

        def on_epoch_end(self, epoch, logs=None):
            logs = logs or {}
            msg = f"Model {self.model_iteration}: " + ", ".join([f"{k}={v:.4f}" for k, v in logs.items()])
            print(f"\r{msg}", end='')

        def on_train_end(self, logs=None):
            print()
            print()

    def fit(self, max_iterations: int = 1, verbose: int = 1) -> dict:
        self.max_iterations = max_iterations

        overall_results = {"history": {}, "models": []}

        for iteration in range(max_iterations):
            self.model, response = self.build_model()
            if "epochs" not in self.training_config or "batch_size" not in self.training_config:
                raise ValueError("Training configuration missing; GPT must provide BATCH_SIZE and EPOCHS.")

            epochs = int(self.training_config["epochs"])
            batch_size = int(self.training_config["batch_size"])
            callbacks = self._build_callbacks() 
            if verbose > 0:
                callbacks.append(self.SingleLineLogger(model_iteration=iteration))
            results = self.model.fit(
                self.train_x,
                self.train_y,
                epochs=epochs,
                batch_size=batch_size,
                validation_split=0.2,
                callbacks=callbacks,
                verbose=0,
            )

            overall_results["models"].append(self.model)

            for history_key, history_values in results.history.items():
                if history_key not in overall_results["history"]:
                    overall_results["history"][history_key] = []
                overall_results["history"][history_key].append(history_values[-1])


            if (min(self.best_model_results["val_loss"]) > min(results.history["val_loss"]) and min(self.best_model_results["loss"]) > min(results.history["loss"])) if self.best_model_results is not None else True:
                self.best_model = response
                self.best_model_results = results.history
                self.model.save(self.best_model_path)
                if verbose > 0:
                    print(f"New best model found and saved to {self.best_model_path}")

        return overall_results

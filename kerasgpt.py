from __future__ import annotations

import argparse
import os
from dataclasses import dataclass
from typing import Tuple

import numpy as np
import tensorflow as tf
from tensorflow import keras

class OpenAIChatClient:
    def __init__(self, api_key: str | None = None, model: str = "gpt-4o-mini", system_prompt: str | None = None):
        try:
            from openai import OpenAI
        except ImportError as exc:
            raise ImportError("Install the openai package to use OpenAIChatClient") from exc

        api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OpenAI API key not provided")

        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.messages: list[dict[str, str]] = []
        if system_prompt:
            self.messages.append({"role": "system", "content": system_prompt})

    def chat(self, content: str, role: str = "user", **kwargs) -> str:
        if not content:
            raise ValueError("Message content must be provided")

        self.messages.append({"role": role, "content": content})
        completion = self.client.chat.completions.create(model=self.model, messages=self.messages, **kwargs)
        message = completion.choices[0].message
        response = message.get("content") if isinstance(message, dict) else getattr(message, "content", "")
        self.messages.append({"role": "assistant", "content": response})
        return response

    def reset(self, system_prompt: str | None = None) -> None:
        self.messages = []
        if system_prompt:
            self.messages.append({"role": "system", "content": system_prompt})

    def history(self) -> list[dict[str, str]]:
        return list(self.messages)




class GPTmodel:
    def __init__(self, train_x, train_y):
        self.train_x = train_x
        self.train_y = train_y
        self.input_shape = tuple(train_x.shape[1:]) if train_x.ndim > 1 else (1,)
        self.num_classes = int(train_y.max()) + 1 if np.issubdtype(train_y.dtype, np.integer) else 1
        self.gpt_client = OpenAIChatClient()
        self.training_config: dict[str, int] = {}

    def build_model(self) -> keras.Model:
        if self.gpt_client is None:
            raise ValueError("OpenAIChatClient instance is required to build the model")

        sample_size = min(5, len(self.train_x))
        sample_inputs = self.train_x[: min(sample_size, len(self.train_x))]
        sample_outputs = self.train_y[: min(sample_size, len(self.train_y))]
        prompt = self._build_prompt(sample_inputs=sample_inputs, sample_outputs=sample_outputs)

        response = self.gpt_client.chat(prompt)

        print("Generated model code:\n", response)

        exec_globals = {"keras": keras, "tf": tf, "np": np}
        exec_locals: dict[str, object] = {}
        try:
            exec(response, exec_globals, exec_locals)
        except Exception as exc:
            raise RuntimeError("Failed to execute model code generated by GPT") from exc

        batch_size = exec_locals.get("BATCH_SIZE")
        epochs = exec_locals.get("EPOCHS")

        if not isinstance(batch_size, (int, np.integer)) or batch_size <= 0:
            raise ValueError("GPT response must define a positive integer BATCH_SIZE constant.")
        if not isinstance(epochs, (int, np.integer)) or epochs <= 0:
            raise ValueError("GPT response must define a positive integer EPOCHS constant.")

        self.training_config["batch_size"] = int(batch_size)
        self.training_config["epochs"] = int(epochs)

        create_model = exec_locals.get("create_model")
        if not callable(create_model):
            raise ValueError("GPT response did not define a callable create_model function")

        model = create_model(input_shape=self.input_shape, num_classes=self.num_classes)
        if not isinstance(model, keras.Model):
            raise TypeError("create_model must return a compiled keras.Model instance")

        return model

    def _build_prompt(self, sample_inputs: np.ndarray, sample_outputs: np.ndarray) -> str:
        input_shape = self.input_shape
        output_shape = tuple(sample_outputs.shape[1:]) if sample_outputs.ndim > 1 else ()
        task_type = "classification" if self.num_classes > 1 else "regression"

        prompt = f"""
You are an expert TensorFlow engineer. Generate Python source code for a function called create_model(input_shape, num_classes) that builds and compiles a tf.keras.Model for a {task_type} problem.
If you know of any previous models that you created and the results they produced then use this information to influence your design.

Project constraints:
- Training input shape: {input_shape}
- Training output shape: {output_shape if output_shape else 'scalar'}
- Number of target classes: {self.num_classes}
- Sample input batch (first {len(sample_inputs)} rows): {sample_inputs.tolist()}
- Sample target values: {sample_outputs.tolist()}

Requirements:
1. The function must be pure Python using tf.keras layers and return a compiled keras.Model instance.
2. For classification tasks, include a final activation appropriate for the number of classes; for regression use a linear output and ignore the num_classes parameter.
3. Compile using keras.optimizers.Adam with a sensible learning rate. Use sparse_categorical_crossentropy with accuracy when num_classes > 1, otherwise use mean_squared_error.
4. Return valid Python that defines create_model(input_shape, num_classes) and sets integer constants BATCH_SIZE and EPOCHS at module scope (outside create_model); do not include explanations or markdown fences.
5. Ensure BATCH_SIZE and EPOCHS are positive integers tailored to the task and data size.
6. Use padding='same' (or otherwise ensure spatial dimensions stay valid) so pooling layers never encounter invalid dimensions for the provided input shape.
7. Start the model with tf.keras.Input(shape=input_shape) and do not pass input_shape directly to other layers.
"""
        return prompt.strip()

    def _can_results_be_improved_prompt(self, history: dict) -> str:
        prompt = f"""
        This is the results of training the model you generated:
        {history}
        Do you think these results can be improved further with a different architecture or training configuration? Answer with a short yes or no and nothing else.
        """
        return prompt.strip()

    def fit(self, max_iterations: int = 1) -> None:

        for iteration in range(max_iterations):
            self.model = self.build_model()
            if "epochs" not in self.training_config or "batch_size" not in self.training_config:
                raise ValueError("Training configuration missing; GPT must provide BATCH_SIZE and EPOCHS.")

            epochs = int(self.training_config["epochs"])
            batch_size = int(self.training_config["batch_size"])
            results = self.model.fit(self.train_x, self.train_y, epochs=epochs, batch_size=batch_size, validation_split=0.2)

            can_results_be_improved = self.gpt_client.chat(self._can_results_be_improved_prompt(results.history)).strip().lower()
            print(can_results_be_improved)

            if "yes" not in can_results_be_improved.lower() and "no" not in can_results_be_improved.lower():
                raise ValueError("GPT response to improvement prompt must be 'yes' or 'no'")

            if "no" in can_results_be_improved.lower():
                print("GPT determined that the model cannot be improved further.")
                break








if __name__ == "__main__":

    from data import load_digits_dataset, load_regression_dataset, load_tabular_classification_dataset

    # Example usage with the digits dataset
    images, labels = load_digits_dataset()
    print(images.shape, labels.shape)
    model = GPTmodel(images, labels)
    model.fit(max_iterations=3)

    # # Example usage with the tabular classification dataset
    # X_class, y_class = load_tabular_classification_dataset()
    # print(X_class.shape, y_class.shape)
    # model_class = GPTmodel(X_class, y_class)
    # model_class.fit()

    # # Example usage with the regression dataset
    # X_reg, y_reg = load_regression_dataset()
    # print(X_reg.shape, y_reg.shape)
    # model_reg = GPTmodel(X_reg, y_reg)
    # model_reg.fit()
